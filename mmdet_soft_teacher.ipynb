{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhGJaamKuDCB",
        "outputId": "144c150b-6320-4a58-ab05-616fe5f468f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title import drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title extracting my data zipfile\n",
        "import zipfile\n",
        "\n",
        "def extract_zip(zip_file_path, destination_folder):\n",
        "    # Open the zip file\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        # Extract all the contents to the destination folder\n",
        "        zip_ref.extractall(destination_folder)\n",
        "\n",
        "# Usage example\n",
        "zip_file_path = '/content/drive/MyDrive/kitti_dataset.zip'\n",
        "destination_folder = '/content/drive/MyDrive'\n",
        "\n",
        "extract_zip(zip_file_path, destination_folder)\n"
      ],
      "metadata": {
        "id": "IIsRPtt77qD9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FINDING EXCESS IMAGES, NO CORRESPONDING ANNOTATIONS\n",
        "import os\n",
        "\n",
        "image_dir = \"/content/drive/MyDrive/kitti_dataset/val_set/images\"\n",
        "annotation_dir = \"/content/drive/MyDrive/kitti_dataset/val_set/annotations\"\n",
        "\n",
        "# Get the list of image files\n",
        "image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
        "\n",
        "# Get the list of annotation files\n",
        "annotation_files = [f for f in os.listdir(annotation_dir) if os.path.isfile(os.path.join(annotation_dir, f))]\n",
        "\n",
        "# Extract the base filenames without extensions\n",
        "image_names = [os.path.splitext(f)[0] for f in image_files]\n",
        "annotation_names = [os.path.splitext(f)[0] for f in annotation_files]\n",
        "\n",
        "# Find images without corresponding annotations\n",
        "missing_annotations = [f for f in image_names if f not in annotation_names]\n",
        "missing_annotations"
      ],
      "metadata": {
        "id": "HRuUj2zS-ap_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1437e11d-ba55-4978-b674-2e177b5863eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title amount of data in train and valid directory\n",
        "import os\n",
        "print(\"train\")\n",
        "print(len(os.listdir('/content/mmdetection/data/coco/train')))\n",
        "print(\"validation\")\n",
        "print(len(os.listdir('/content/mmdetection/data/coco/val')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q709aWaf_sKu",
        "outputId": "0f3802fe-bc4f-4197-a4d5-5b32c63237c6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "500\n",
            "validation\n",
            "6981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import the nessecary libraries\n",
        "!pip3 install openmim\n",
        "!mim install mmengine\n",
        "!mim install \"mmcv>=2.0.0,<2.1.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4IYxkIpuLIB",
        "outputId": "b66f9198-7c59-4a00-da26-0db1b73bd193"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openmim\n",
            "  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.3)\n",
            "Collecting colorama (from openmim)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.27.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.3.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.8.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.4.3)\n",
            "Collecting ordered-set (from model-index->openmim)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.22.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n",
            "Installing collected packages: ordered-set, colorama, model-index, openmim\n",
            "Successfully installed colorama-0.4.6 model-index-0.1.11 openmim-0.3.7 ordered-set-4.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Collecting mmengine\n",
            "  Downloading mmengine-0.7.4-py3-none-any.whl (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.3/374.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmengine)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine) (1.22.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine) (6.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine) (13.3.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.3.0)\n",
            "Collecting yapf (from mmengine)\n",
            "  Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine) (4.7.0.72)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.14.0)\n",
            "Collecting importlib-metadata>=6.6.0 (from yapf->mmengine)\n",
            "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting platformdirs>=3.5.1 (from yapf->mmengine)\n",
            "  Downloading platformdirs-3.7.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->mmengine) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\n",
            "Installing collected packages: addict, platformdirs, importlib-metadata, yapf, mmengine\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 3.3.0\n",
            "    Uninstalling platformdirs-3.3.0:\n",
            "      Successfully uninstalled platformdirs-3.3.0\n",
            "Successfully installed addict-2.4.0 importlib-metadata-6.7.0 mmengine-0.7.4 platformdirs-3.7.0 yapf-0.40.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Collecting mmcv<2.1.0,>=2.0.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/mmcv-2.0.0-cp310-cp310-manylinux1_x86_64.whl (74.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (0.7.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (8.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (6.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (0.40.1)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0) (4.7.0.72)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (13.3.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (2.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.1.0,>=2.0.0) (6.7.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.1.0,>=2.0.0) (3.7.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.1.0,>=2.0.0) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv<2.1.0,>=2.0.0) (3.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.2.0->mmcv<2.1.0,>=2.0.0) (1.16.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title clone repository\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GejNH1Bu2lF",
        "outputId": "e583902e-6654-42a8-ca75-77863c09d76f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 36530, done.\u001b[K\n",
            "remote: Counting objects: 100% (1175/1175), done.\u001b[K\n",
            "remote: Compressing objects: 100% (701/701), done.\u001b[K\n",
            "remote: Total 36530 (delta 619), reused 838 (delta 460), pack-reused 35355\u001b[K\n",
            "Receiving objects: 100% (36530/36530), 56.89 MiB | 9.53 MiB/s, done.\n",
            "Resolving deltas: 100% (25555/25555), done.\n",
            "/content/mmdetection\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/mmdetection\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet==3.0.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet==3.0.0) (1.22.4)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet==3.0.0) (2.0.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet==3.0.0) (1.10.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet==3.0.0) (1.16.0)\n",
            "Collecting terminaltables (from mmdet==3.0.0)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.0.0) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.0.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.0.0) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.0.0) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.0.0) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.0.0) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.0.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.0.0) (2.8.2)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-3.0.0 terminaltables-3.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title copy from drive to mmdetection imported directory or repo\n",
        "import shutil\n",
        "\n",
        "# Specify the source file path\n",
        "source_file = '/content/drive/MyDrive/val_coco_annotations.json'\n",
        "\n",
        "# Specify the destination directory\n",
        "destination_dir = '/content/mmdetection/data/coco/annotations/'\n",
        "\n",
        "# Use shutil.copy() to copy the file\n",
        "shutil.copy(source_file, destination_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HNi_gX7hHS5Q",
        "outputId": "d3a05bb6-f380-4571-b138-39a807c9929c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/mmdetection/data/coco/annotations/val_coco_annotations.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the source file path\n",
        "source_file = '/content/drive/MyDrive/coco_annotations.json'\n",
        "\n",
        "# Specify the destination directory\n",
        "destination_dir = '/content/mmdetection/data/coco/annotations/'\n",
        "\n",
        "# Use shutil.copy() to copy the file\n",
        "shutil.copy(source_file, destination_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YP_om9BmHeqB",
        "outputId": "b963aec0-91e5-4293-a66f-a267877b6560"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/mmdetection/data/coco/annotations/coco_annotations.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title this is to do same with images\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def copy_images(source_folder, destination_folder):\n",
        "    # Get a list of all files in the source folder\n",
        "    file_list = os.listdir(source_folder)\n",
        "\n",
        "    # Iterate over each file in the source folder\n",
        "    for file_name in file_list:\n",
        "        # Construct the full path to the source file\n",
        "        source_file = os.path.join(source_folder, file_name)\n",
        "\n",
        "        # Check if the current file is a valid image file\n",
        "        if file_name.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
        "            # Construct the full path to the destination file\n",
        "            destination_file = os.path.join(destination_folder, file_name)\n",
        "\n",
        "            # Copy the file from the source folder to the destination folder\n",
        "            shutil.copy2(source_file, destination_file)\n",
        "\n",
        "# Specify the source and destination folders\n",
        "source_folder = '/content/drive/MyDrive/kitti_dataset/raw_set/images'\n",
        "destination_folder = '/content/mmdetection/data/coco/train'\n",
        "\n",
        "# Call the function to copy images from the source folder to the destination folder\n",
        "copy_images(source_folder, destination_folder)\n"
      ],
      "metadata": {
        "id": "UXlYjROTH6W3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def copy_images(source_folder, destination_folder):\n",
        "    # Get a list of all files in the source folder\n",
        "    file_list = os.listdir(source_folder)\n",
        "\n",
        "    # Iterate over each file in the source folder\n",
        "    for file_name in file_list:\n",
        "        # Construct the full path to the source file\n",
        "        source_file = os.path.join(source_folder, file_name)\n",
        "\n",
        "        # Check if the current file is a valid image file\n",
        "        if file_name.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
        "            # Construct the full path to the destination file\n",
        "            destination_file = os.path.join(destination_folder, file_name)\n",
        "\n",
        "            # Copy the file from the source folder to the destination folder\n",
        "            shutil.copy2(source_file, destination_file)\n",
        "\n",
        "# Specify the source and destination folders\n",
        "source_folder = '/content/drive/MyDrive/kitti_dataset/val_set/images'\n",
        "destination_folder = '/content/mmdetection/data/coco/val'\n",
        "\n",
        "# Call the function to copy images from the source folder to the destination folder\n",
        "copy_images(source_folder, destination_folder)\n"
      ],
      "metadata": {
        "id": "QLbbBl-YLbT5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(len(os.listdir('/content/mmdetection/data/coco/train')))\n",
        "print(len(os.listdir('/content/mmdetection/data/coco/val')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV0Rkid0LfsE",
        "outputId": "ddb9aad7-5657-4981-a21e-08d82567dba3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "6981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title conversion of all the .png images in train, val directory to .jpg images\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def convert_png_to_jpg(source_folder, destination_folder):\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    if not os.path.exists(destination_folder):\n",
        "        os.makedirs(destination_folder)\n",
        "\n",
        "    # Get a list of all files in the source folder\n",
        "    file_list = os.listdir(source_folder)\n",
        "\n",
        "    # Iterate over each file in the source folder\n",
        "    for file_name in file_list:\n",
        "        # Construct the full path to the source file\n",
        "        source_file = os.path.join(source_folder, file_name)\n",
        "\n",
        "        # Check if the current file is a PNG image\n",
        "        if file_name.lower().endswith('.png'):\n",
        "            # Open the PNG image\n",
        "            png_image = Image.open(source_file)\n",
        "\n",
        "            # Convert the PNG image to JPEG\n",
        "            jpg_image = png_image.convert('RGB')\n",
        "\n",
        "            # Construct the full path to the destination file with a .jpg extension\n",
        "            destination_file = os.path.join(destination_folder, file_name.rsplit('.', 1)[0] + '.jpg')\n",
        "\n",
        "            # Save the converted image as JPEG\n",
        "            jpg_image.save(destination_file, 'JPEG')\n",
        "\n",
        "# Specify the source and destination folders\n",
        "source_folder = '/content/mmdetection/data/coco/train'\n",
        "destination_folder = '/content/mmdetection/data/coco/train2'\n",
        "\n",
        "# Call the function to convert PNG images to JPEG and store them in the destination folder\n",
        "convert_png_to_jpg(source_folder, destination_folder)\n"
      ],
      "metadata": {
        "id": "Io9YceLkOk0c"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def convert_png_to_jpg(source_folder, destination_folder):\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    if not os.path.exists(destination_folder):\n",
        "        os.makedirs(destination_folder)\n",
        "\n",
        "    # Get a list of all files in the source folder\n",
        "    file_list = os.listdir(source_folder)\n",
        "\n",
        "    # Iterate over each file in the source folder\n",
        "    for file_name in file_list:\n",
        "        # Construct the full path to the source file\n",
        "        source_file = os.path.join(source_folder, file_name)\n",
        "\n",
        "        # Check if the current file is a PNG image\n",
        "        if file_name.lower().endswith('.png'):\n",
        "            # Open the PNG image\n",
        "            png_image = Image.open(source_file)\n",
        "\n",
        "            # Convert the PNG image to JPEG\n",
        "            jpg_image = png_image.convert('RGB')\n",
        "\n",
        "            # Construct the full path to the destination file with a .jpg extension\n",
        "            destination_file = os.path.join(destination_folder, file_name.rsplit('.', 1)[0] + '.jpg')\n",
        "\n",
        "            # Save the converted image as JPEG\n",
        "            jpg_image.save(destination_file, 'JPEG')\n",
        "\n",
        "# Specify the source and destination folders\n",
        "source_folder = '/content/mmdetection/data/coco/val'\n",
        "destination_folder = '/content/mmdetection/data/coco/val2'\n",
        "\n",
        "# Call the function to convert PNG images to JPEG and store them in the destination folder\n",
        "convert_png_to_jpg(source_folder, destination_folder)\n"
      ],
      "metadata": {
        "id": "mUYQuF86O4zx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(len(os.listdir('/content/mmdetection/data/coco/train2')))\n",
        "print(len(os.listdir('/content/mmdetection/data/coco/val2')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d36bJ8PQbJZ",
        "outputId": "5bcc27a3-601c-4a0c-bb14-d75e9c27ca30"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "6981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtsDoIw_Khia",
        "outputId": "dfd9bcd1-2a15-47d6-e57e-1efe74b3a0e8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title removing the .png images containing directory\n",
        "import shutil\n",
        "\n",
        "def remove_folder(folder_path):\n",
        "    # Delete the folder and its contents\n",
        "    shutil.rmtree(folder_path)\n",
        "\n",
        "# Usage example\n",
        "folder_path = '/content/mmdetection/data/coco/train'\n",
        "\n",
        "remove_folder(folder_path)"
      ],
      "metadata": {
        "id": "87xmtVPUI4sQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def remove_folder(folder_path):\n",
        "    # Delete the folder and its contents\n",
        "    shutil.rmtree(folder_path)\n",
        "\n",
        "# Usage example\n",
        "folder_path = '/content/mmdetection/data/coco/val'\n",
        "\n",
        "remove_folder(folder_path)"
      ],
      "metadata": {
        "id": "Nf8XuuusRD_h"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title change path to mmdetection as to proper working of config files\n",
        "%cd /content/mmdetection"
      ],
      "metadata": {
        "id": "EB9UEA_oxYCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9988144-bb56-4fa4-80ec-d51e3e8cfef4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmdetection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nUTj8A2sUpBu",
        "outputId": "1b413781-aabe-45ee-d6a5-2dccae572f89"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/mmdetection'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title train the model\n",
        "!python tools/train.py configs/soft_teacher/soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VVUh5UPUsLA",
        "outputId": "19b27a10-7008-4388-ab1f-31b65d6cec15"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06/21 09:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0]\n",
            "    CUDA available: False\n",
            "    numpy_random_seed: 1319573268\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.7.0\n",
            "    MMEngine: 0.7.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1319573268\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "06/21 09:13:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "model = dict(\n",
            "    type='SoftTeacher',\n",
            "    detector=dict(\n",
            "        type='FasterRCNN',\n",
            "        data_preprocessor=dict(\n",
            "            type='DetDataPreprocessor',\n",
            "            mean=[103.53, 116.28, 123.675],\n",
            "            std=[1.0, 1.0, 1.0],\n",
            "            bgr_to_rgb=False,\n",
            "            pad_size_divisor=32),\n",
            "        backbone=dict(\n",
            "            type='ResNet',\n",
            "            depth=50,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=False),\n",
            "            norm_eval=True,\n",
            "            style='caffe',\n",
            "            init_cfg=dict(\n",
            "                type='Pretrained',\n",
            "                checkpoint='open-mmlab://detectron2/resnet50_caffe')),\n",
            "        neck=dict(\n",
            "            type='FPN',\n",
            "            in_channels=[256, 512, 1024, 2048],\n",
            "            out_channels=256,\n",
            "            num_outs=5),\n",
            "        rpn_head=dict(\n",
            "            type='RPNHead',\n",
            "            in_channels=256,\n",
            "            feat_channels=256,\n",
            "            anchor_generator=dict(\n",
            "                type='AnchorGenerator',\n",
            "                scales=[8],\n",
            "                ratios=[0.5, 1.0, 2.0],\n",
            "                strides=[4, 8, 16, 32, 64]),\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "        roi_head=dict(\n",
            "            type='StandardRoIHead',\n",
            "            bbox_roi_extractor=dict(\n",
            "                type='SingleRoIExtractor',\n",
            "                roi_layer=dict(\n",
            "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "                out_channels=256,\n",
            "                featmap_strides=[4, 8, 16, 32]),\n",
            "            bbox_head=dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=80,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
            "        train_cfg=dict(\n",
            "            rpn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.7,\n",
            "                    neg_iou_thr=0.3,\n",
            "                    min_pos_iou=0.3,\n",
            "                    match_low_quality=True,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=256,\n",
            "                    pos_fraction=0.5,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=False),\n",
            "                allowed_border=-1,\n",
            "                pos_weight=-1,\n",
            "                debug=False),\n",
            "            rpn_proposal=dict(\n",
            "                nms_pre=2000,\n",
            "                max_per_img=1000,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    min_pos_iou=0.5,\n",
            "                    match_low_quality=False,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=True),\n",
            "                pos_weight=-1,\n",
            "                debug=False)),\n",
            "        test_cfg=dict(\n",
            "            rpn=dict(\n",
            "                nms_pre=1000,\n",
            "                max_per_img=1000,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                score_thr=0.05,\n",
            "                nms=dict(type='nms', iou_threshold=0.5),\n",
            "                max_per_img=100))),\n",
            "    data_preprocessor=dict(\n",
            "        type='MultiBranchDataPreprocessor',\n",
            "        data_preprocessor=dict(\n",
            "            type='DetDataPreprocessor',\n",
            "            mean=[103.53, 116.28, 123.675],\n",
            "            std=[1.0, 1.0, 1.0],\n",
            "            bgr_to_rgb=False,\n",
            "            pad_size_divisor=32)),\n",
            "    semi_train_cfg=dict(\n",
            "        freeze_teacher=True,\n",
            "        sup_weight=1.0,\n",
            "        unsup_weight=4.0,\n",
            "        pseudo_label_initial_score_thr=0.5,\n",
            "        rpn_pseudo_thr=0.9,\n",
            "        cls_pseudo_thr=0.9,\n",
            "        reg_pseudo_thr=0.02,\n",
            "        jitter_times=10,\n",
            "        jitter_scale=0.06,\n",
            "        min_pseudo_bbox_wh=(0.01, 0.01)),\n",
            "    semi_test_cfg=dict(predict_on='teacher'))\n",
            "default_scope = 'mmdet'\n",
            "default_hooks = dict(\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=50),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(\n",
            "        type='CheckpointHook',\n",
            "        interval=10000,\n",
            "        by_epoch=False,\n",
            "        max_keep_ckpts=2),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    visualization=dict(type='DetVisualizationHook'))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "vis_backends = [dict(type='LocalVisBackend')]\n",
            "visualizer = dict(\n",
            "    type='DetLocalVisualizer',\n",
            "    vis_backends=[dict(type='LocalVisBackend')],\n",
            "    name='visualizer')\n",
            "log_processor = dict(type='LogProcessor', window_size=50, by_epoch=False)\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume = False\n",
            "dataset_type = 'CocoDataset'\n",
            "data_root = 'data/coco/'\n",
            "backend_args = None\n",
            "color_space = [[{\n",
            "    'type': 'ColorTransform'\n",
            "}], [{\n",
            "    'type': 'AutoContrast'\n",
            "}], [{\n",
            "    'type': 'Equalize'\n",
            "}], [{\n",
            "    'type': 'Sharpness'\n",
            "}], [{\n",
            "    'type': 'Posterize'\n",
            "}], [{\n",
            "    'type': 'Solarize'\n",
            "}], [{\n",
            "    'type': 'Color'\n",
            "}], [{\n",
            "    'type': 'Contrast'\n",
            "}], [{\n",
            "    'type': 'Brightness'\n",
            "}]]\n",
            "geometric = [[{\n",
            "    'type': 'Rotate'\n",
            "}], [{\n",
            "    'type': 'ShearX'\n",
            "}], [{\n",
            "    'type': 'ShearY'\n",
            "}], [{\n",
            "    'type': 'TranslateX'\n",
            "}], [{\n",
            "    'type': 'TranslateY'\n",
            "}]]\n",
            "scale = [(1333, 400), (1333, 1200)]\n",
            "branch_field = ['sup', 'unsup_teacher', 'unsup_student']\n",
            "sup_pipeline = [\n",
            "    dict(type='LoadImageFromFile', backend_args=None),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        type='RandomResize',\n",
            "        scale=[(1333, 400), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='RandomFlip', prob=0.5),\n",
            "    dict(\n",
            "        type='RandAugment',\n",
            "        aug_space=[[{\n",
            "            'type': 'ColorTransform'\n",
            "        }], [{\n",
            "            'type': 'AutoContrast'\n",
            "        }], [{\n",
            "            'type': 'Equalize'\n",
            "        }], [{\n",
            "            'type': 'Sharpness'\n",
            "        }], [{\n",
            "            'type': 'Posterize'\n",
            "        }], [{\n",
            "            'type': 'Solarize'\n",
            "        }], [{\n",
            "            'type': 'Color'\n",
            "        }], [{\n",
            "            'type': 'Contrast'\n",
            "        }], [{\n",
            "            'type': 'Brightness'\n",
            "        }]],\n",
            "        aug_num=1),\n",
            "    dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),\n",
            "    dict(\n",
            "        type='MultiBranch',\n",
            "        branch_field=['sup', 'unsup_teacher', 'unsup_student'],\n",
            "        sup=dict(type='PackDetInputs'))\n",
            "]\n",
            "weak_pipeline = [\n",
            "    dict(\n",
            "        type='RandomResize',\n",
            "        scale=[(1333, 400), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='RandomFlip', prob=0.5),\n",
            "    dict(\n",
            "        type='PackDetInputs',\n",
            "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                   'scale_factor', 'flip', 'flip_direction',\n",
            "                   'homography_matrix'))\n",
            "]\n",
            "strong_pipeline = [\n",
            "    dict(\n",
            "        type='RandomResize',\n",
            "        scale=[(1333, 400), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='RandomFlip', prob=0.5),\n",
            "    dict(\n",
            "        type='RandomOrder',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RandAugment',\n",
            "                aug_space=[[{\n",
            "                    'type': 'ColorTransform'\n",
            "                }], [{\n",
            "                    'type': 'AutoContrast'\n",
            "                }], [{\n",
            "                    'type': 'Equalize'\n",
            "                }], [{\n",
            "                    'type': 'Sharpness'\n",
            "                }], [{\n",
            "                    'type': 'Posterize'\n",
            "                }], [{\n",
            "                    'type': 'Solarize'\n",
            "                }], [{\n",
            "                    'type': 'Color'\n",
            "                }], [{\n",
            "                    'type': 'Contrast'\n",
            "                }], [{\n",
            "                    'type': 'Brightness'\n",
            "                }]],\n",
            "                aug_num=1),\n",
            "            dict(\n",
            "                type='RandAugment',\n",
            "                aug_space=[[{\n",
            "                    'type': 'Rotate'\n",
            "                }], [{\n",
            "                    'type': 'ShearX'\n",
            "                }], [{\n",
            "                    'type': 'ShearY'\n",
            "                }], [{\n",
            "                    'type': 'TranslateX'\n",
            "                }], [{\n",
            "                    'type': 'TranslateY'\n",
            "                }]],\n",
            "                aug_num=1)\n",
            "        ]),\n",
            "    dict(type='RandomErasing', n_patches=(1, 5), ratio=(0, 0.2)),\n",
            "    dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),\n",
            "    dict(\n",
            "        type='PackDetInputs',\n",
            "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                   'scale_factor', 'flip', 'flip_direction',\n",
            "                   'homography_matrix'))\n",
            "]\n",
            "unsup_pipeline = [\n",
            "    dict(type='LoadImageFromFile', backend_args=None),\n",
            "    dict(type='LoadEmptyAnnotations'),\n",
            "    dict(\n",
            "        type='MultiBranch',\n",
            "        branch_field=['sup', 'unsup_teacher', 'unsup_student'],\n",
            "        unsup_teacher=[\n",
            "            dict(\n",
            "                type='RandomResize',\n",
            "                scale=[(1333, 400), (1333, 1200)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='RandomFlip', prob=0.5),\n",
            "            dict(\n",
            "                type='PackDetInputs',\n",
            "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                           'scale_factor', 'flip', 'flip_direction',\n",
            "                           'homography_matrix'))\n",
            "        ],\n",
            "        unsup_student=[\n",
            "            dict(\n",
            "                type='RandomResize',\n",
            "                scale=[(1333, 400), (1333, 1200)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='RandomFlip', prob=0.5),\n",
            "            dict(\n",
            "                type='RandomOrder',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RandAugment',\n",
            "                        aug_space=[[{\n",
            "                            'type': 'ColorTransform'\n",
            "                        }], [{\n",
            "                            'type': 'AutoContrast'\n",
            "                        }], [{\n",
            "                            'type': 'Equalize'\n",
            "                        }], [{\n",
            "                            'type': 'Sharpness'\n",
            "                        }], [{\n",
            "                            'type': 'Posterize'\n",
            "                        }], [{\n",
            "                            'type': 'Solarize'\n",
            "                        }], [{\n",
            "                            'type': 'Color'\n",
            "                        }], [{\n",
            "                            'type': 'Contrast'\n",
            "                        }], [{\n",
            "                            'type': 'Brightness'\n",
            "                        }]],\n",
            "                        aug_num=1),\n",
            "                    dict(\n",
            "                        type='RandAugment',\n",
            "                        aug_space=[[{\n",
            "                            'type': 'Rotate'\n",
            "                        }], [{\n",
            "                            'type': 'ShearX'\n",
            "                        }], [{\n",
            "                            'type': 'ShearY'\n",
            "                        }], [{\n",
            "                            'type': 'TranslateX'\n",
            "                        }], [{\n",
            "                            'type': 'TranslateY'\n",
            "                        }]],\n",
            "                        aug_num=1)\n",
            "                ]),\n",
            "            dict(type='RandomErasing', n_patches=(1, 5), ratio=(0, 0.2)),\n",
            "            dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),\n",
            "            dict(\n",
            "                type='PackDetInputs',\n",
            "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                           'scale_factor', 'flip', 'flip_direction',\n",
            "                           'homography_matrix'))\n",
            "        ])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile', backend_args=None),\n",
            "    dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
            "    dict(\n",
            "        type='PackDetInputs',\n",
            "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                   'scale_factor'))\n",
            "]\n",
            "batch_size = 5\n",
            "num_workers = 5\n",
            "labeled_dataset = dict(\n",
            "    type='CocoDataset',\n",
            "    data_root='data/coco/',\n",
            "    ann_file='annotations/coco_annotations.json',\n",
            "    data_prefix=dict(img='train/'),\n",
            "    filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile', backend_args=None),\n",
            "        dict(type='LoadAnnotations', with_bbox=True),\n",
            "        dict(\n",
            "            type='RandomResize',\n",
            "            scale=[(1333, 400), (1333, 1200)],\n",
            "            keep_ratio=True),\n",
            "        dict(type='RandomFlip', prob=0.5),\n",
            "        dict(\n",
            "            type='RandAugment',\n",
            "            aug_space=[[{\n",
            "                'type': 'ColorTransform'\n",
            "            }], [{\n",
            "                'type': 'AutoContrast'\n",
            "            }], [{\n",
            "                'type': 'Equalize'\n",
            "            }], [{\n",
            "                'type': 'Sharpness'\n",
            "            }], [{\n",
            "                'type': 'Posterize'\n",
            "            }], [{\n",
            "                'type': 'Solarize'\n",
            "            }], [{\n",
            "                'type': 'Color'\n",
            "            }], [{\n",
            "                'type': 'Contrast'\n",
            "            }], [{\n",
            "                'type': 'Brightness'\n",
            "            }]],\n",
            "            aug_num=1),\n",
            "        dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),\n",
            "        dict(\n",
            "            type='MultiBranch',\n",
            "            branch_field=['sup', 'unsup_teacher', 'unsup_student'],\n",
            "            sup=dict(type='PackDetInputs'))\n",
            "    ],\n",
            "    backend_args=None)\n",
            "unlabeled_dataset = dict(\n",
            "    type='CocoDataset',\n",
            "    data_root='data/coco/',\n",
            "    ann_file='annotations/val_coco_annotations.json',\n",
            "    data_prefix=dict(img='val/'),\n",
            "    filter_cfg=dict(filter_empty_gt=False),\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile', backend_args=None),\n",
            "        dict(type='LoadEmptyAnnotations'),\n",
            "        dict(\n",
            "            type='MultiBranch',\n",
            "            branch_field=['sup', 'unsup_teacher', 'unsup_student'],\n",
            "            unsup_teacher=[\n",
            "                dict(\n",
            "                    type='RandomResize',\n",
            "                    scale=[(1333, 400), (1333, 1200)],\n",
            "                    keep_ratio=True),\n",
            "                dict(type='RandomFlip', prob=0.5),\n",
            "                dict(\n",
            "                    type='PackDetInputs',\n",
            "                    meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                               'scale_factor', 'flip', 'flip_direction',\n",
            "                               'homography_matrix'))\n",
            "            ],\n",
            "            unsup_student=[\n",
            "                dict(\n",
            "                    type='RandomResize',\n",
            "                    scale=[(1333, 400), (1333, 1200)],\n",
            "                    keep_ratio=True),\n",
            "                dict(type='RandomFlip', prob=0.5),\n",
            "                dict(\n",
            "                    type='RandomOrder',\n",
            "                    transforms=[\n",
            "                        dict(\n",
            "                            type='RandAugment',\n",
            "                            aug_space=[[{\n",
            "                                'type': 'ColorTransform'\n",
            "                            }], [{\n",
            "                                'type': 'AutoContrast'\n",
            "                            }], [{\n",
            "                                'type': 'Equalize'\n",
            "                            }], [{\n",
            "                                'type': 'Sharpness'\n",
            "                            }], [{\n",
            "                                'type': 'Posterize'\n",
            "                            }], [{\n",
            "                                'type': 'Solarize'\n",
            "                            }], [{\n",
            "                                'type': 'Color'\n",
            "                            }], [{\n",
            "                                'type': 'Contrast'\n",
            "                            }], [{\n",
            "                                'type': 'Brightness'\n",
            "                            }]],\n",
            "                            aug_num=1),\n",
            "                        dict(\n",
            "                            type='RandAugment',\n",
            "                            aug_space=[[{\n",
            "                                'type': 'Rotate'\n",
            "                            }], [{\n",
            "                                'type': 'ShearX'\n",
            "                            }], [{\n",
            "                                'type': 'ShearY'\n",
            "                            }], [{\n",
            "                                'type': 'TranslateX'\n",
            "                            }], [{\n",
            "                                'type': 'TranslateY'\n",
            "                            }]],\n",
            "                            aug_num=1)\n",
            "                    ]),\n",
            "                dict(type='RandomErasing', n_patches=(1, 5), ratio=(0, 0.2)),\n",
            "                dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),\n",
            "                dict(\n",
            "                    type='PackDetInputs',\n",
            "                    meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                               'scale_factor', 'flip', 'flip_direction',\n",
            "                               'homography_matrix'))\n",
            "            ])\n",
            "    ],\n",
            "    backend_args=None)\n",
            "train_dataloader = dict(\n",
            "    batch_size=5,\n",
            "    num_workers=5,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(\n",
            "        type='GroupMultiSourceSampler', batch_size=5, source_ratio=[1, 4]),\n",
            "    dataset=dict(\n",
            "        type='ConcatDataset',\n",
            "        datasets=[\n",
            "            dict(\n",
            "                type='CocoDataset',\n",
            "                data_root='data/coco/',\n",
            "                ann_file='annotations/coco_annotations.json',\n",
            "                data_prefix=dict(img='train/'),\n",
            "                filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile', backend_args=None),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                    dict(\n",
            "                        type='RandomResize',\n",
            "                        scale=[(1333, 400), (1333, 1200)],\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', prob=0.5),\n",
            "                    dict(\n",
            "                        type='RandAugment',\n",
            "                        aug_space=[[{\n",
            "                            'type': 'ColorTransform'\n",
            "                        }], [{\n",
            "                            'type': 'AutoContrast'\n",
            "                        }], [{\n",
            "                            'type': 'Equalize'\n",
            "                        }], [{\n",
            "                            'type': 'Sharpness'\n",
            "                        }], [{\n",
            "                            'type': 'Posterize'\n",
            "                        }], [{\n",
            "                            'type': 'Solarize'\n",
            "                        }], [{\n",
            "                            'type': 'Color'\n",
            "                        }], [{\n",
            "                            'type': 'Contrast'\n",
            "                        }], [{\n",
            "                            'type': 'Brightness'\n",
            "                        }]],\n",
            "                        aug_num=1),\n",
            "                    dict(\n",
            "                        type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),\n",
            "                    dict(\n",
            "                        type='MultiBranch',\n",
            "                        branch_field=['sup', 'unsup_teacher', 'unsup_student'],\n",
            "                        sup=dict(type='PackDetInputs'))\n",
            "                ],\n",
            "                backend_args=None),\n",
            "            dict(\n",
            "                type='CocoDataset',\n",
            "                data_root='data/coco/',\n",
            "                ann_file='annotations/val_coco_annotations.json',\n",
            "                data_prefix=dict(img='val/'),\n",
            "                filter_cfg=dict(filter_empty_gt=False),\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile', backend_args=None),\n",
            "                    dict(type='LoadEmptyAnnotations'),\n",
            "                    dict(\n",
            "                        type='MultiBranch',\n",
            "                        branch_field=['sup', 'unsup_teacher', 'unsup_student'],\n",
            "                        unsup_teacher=[\n",
            "                            dict(\n",
            "                                type='RandomResize',\n",
            "                                scale=[(1333, 400), (1333, 1200)],\n",
            "                                keep_ratio=True),\n",
            "                            dict(type='RandomFlip', prob=0.5),\n",
            "                            dict(\n",
            "                                type='PackDetInputs',\n",
            "                                meta_keys=('img_id', 'img_path', 'ori_shape',\n",
            "                                           'img_shape', 'scale_factor', 'flip',\n",
            "                                           'flip_direction',\n",
            "                                           'homography_matrix'))\n",
            "                        ],\n",
            "                        unsup_student=[\n",
            "                            dict(\n",
            "                                type='RandomResize',\n",
            "                                scale=[(1333, 400), (1333, 1200)],\n",
            "                                keep_ratio=True),\n",
            "                            dict(type='RandomFlip', prob=0.5),\n",
            "                            dict(\n",
            "                                type='RandomOrder',\n",
            "                                transforms=[\n",
            "                                    dict(\n",
            "                                        type='RandAugment',\n",
            "                                        aug_space=[[{\n",
            "                                            'type': 'ColorTransform'\n",
            "                                        }], [{\n",
            "                                            'type': 'AutoContrast'\n",
            "                                        }], [{\n",
            "                                            'type': 'Equalize'\n",
            "                                        }], [{\n",
            "                                            'type': 'Sharpness'\n",
            "                                        }], [{\n",
            "                                            'type': 'Posterize'\n",
            "                                        }], [{\n",
            "                                            'type': 'Solarize'\n",
            "                                        }], [{\n",
            "                                            'type': 'Color'\n",
            "                                        }], [{\n",
            "                                            'type': 'Contrast'\n",
            "                                        }], [{\n",
            "                                            'type': 'Brightness'\n",
            "                                        }]],\n",
            "                                        aug_num=1),\n",
            "                                    dict(\n",
            "                                        type='RandAugment',\n",
            "                                        aug_space=[[{\n",
            "                                            'type': 'Rotate'\n",
            "                                        }], [{\n",
            "                                            'type': 'ShearX'\n",
            "                                        }], [{\n",
            "                                            'type': 'ShearY'\n",
            "                                        }], [{\n",
            "                                            'type': 'TranslateX'\n",
            "                                        }], [{\n",
            "                                            'type': 'TranslateY'\n",
            "                                        }]],\n",
            "                                        aug_num=1)\n",
            "                                ]),\n",
            "                            dict(\n",
            "                                type='RandomErasing',\n",
            "                                n_patches=(1, 5),\n",
            "                                ratio=(0, 0.2)),\n",
            "                            dict(\n",
            "                                type='FilterAnnotations',\n",
            "                                min_gt_bbox_wh=(0.01, 0.01)),\n",
            "                            dict(\n",
            "                                type='PackDetInputs',\n",
            "                                meta_keys=('img_id', 'img_path', 'ori_shape',\n",
            "                                           'img_shape', 'scale_factor', 'flip',\n",
            "                                           'flip_direction',\n",
            "                                           'homography_matrix'))\n",
            "                        ])\n",
            "                ],\n",
            "                backend_args=None)\n",
            "        ]))\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    drop_last=False,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='CocoDataset',\n",
            "        data_root='data/coco/',\n",
            "        ann_file='annotations/val_coco_annotations.json',\n",
            "        data_prefix=dict(img='val/'),\n",
            "        test_mode=True,\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile', backend_args=None),\n",
            "            dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
            "            dict(\n",
            "                type='PackDetInputs',\n",
            "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                           'scale_factor'))\n",
            "        ],\n",
            "        backend_args=None))\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    drop_last=False,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='CocoDataset',\n",
            "        data_root='data/coco/',\n",
            "        ann_file='annotations/val_coco_annotations.json',\n",
            "        data_prefix=dict(img='val/'),\n",
            "        test_mode=True,\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile', backend_args=None),\n",
            "            dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
            "            dict(\n",
            "                type='PackDetInputs',\n",
            "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                           'scale_factor'))\n",
            "        ],\n",
            "        backend_args=None))\n",
            "val_evaluator = dict(\n",
            "    type='CocoMetric',\n",
            "    ann_file='data/coco/annotations/val_coco_annotations.json',\n",
            "    metric='bbox',\n",
            "    format_only=False,\n",
            "    backend_args=None)\n",
            "test_evaluator = dict(\n",
            "    type='CocoMetric',\n",
            "    ann_file='data/coco/annotations/val_coco_annotations.json',\n",
            "    metric='bbox',\n",
            "    format_only=False,\n",
            "    backend_args=None)\n",
            "detector = dict(\n",
            "    type='FasterRCNN',\n",
            "    data_preprocessor=dict(\n",
            "        type='DetDataPreprocessor',\n",
            "        mean=[103.53, 116.28, 123.675],\n",
            "        std=[1.0, 1.0, 1.0],\n",
            "        bgr_to_rgb=False,\n",
            "        pad_size_divisor=32),\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=False),\n",
            "        norm_eval=True,\n",
            "        style='caffe',\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained',\n",
            "            checkpoint='open-mmlab://detectron2/resnet50_caffe')),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='StandardRoIHead',\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        bbox_head=dict(\n",
            "            type='Shared2FCBBoxHead',\n",
            "            in_channels=256,\n",
            "            fc_out_channels=1024,\n",
            "            roi_feat_size=7,\n",
            "            num_classes=80,\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "            reg_class_agnostic=False,\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
            "    train_cfg=dict(\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.3,\n",
            "                min_pos_iou=0.3,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=False),\n",
            "            allowed_border=-1,\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        rpn_proposal=dict(\n",
            "            nms_pre=2000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)),\n",
            "    test_cfg=dict(\n",
            "        rpn=dict(\n",
            "            nms_pre=1000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            score_thr=0.05,\n",
            "            nms=dict(type='nms', iou_threshold=0.5),\n",
            "            max_per_img=100)))\n",
            "train_cfg = dict(\n",
            "    type='IterBasedTrainLoop', max_iters=180000, val_interval=5000)\n",
            "val_cfg = dict(type='TeacherStudentValLoop')\n",
            "test_cfg = dict(type='TestLoop')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        type='LinearLR', start_factor=0.001, by_epoch=False, begin=0, end=500),\n",
            "    dict(\n",
            "        type='MultiStepLR',\n",
            "        begin=0,\n",
            "        end=180000,\n",
            "        by_epoch=False,\n",
            "        milestones=[120000, 160000],\n",
            "        gamma=0.1)\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    type='OptimWrapper',\n",
            "    optimizer=dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001))\n",
            "custom_hooks = [dict(type='MeanTeacherHook')]\n",
            "launcher = 'none'\n",
            "work_dir = './work_dirs/soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco'\n",
            "\n",
            "06/21 09:13:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "06/21 09:13:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) MeanTeacherHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) MeanTeacherHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loading annotations into memory...\n",
            "Done (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "06/21 09:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://detectron2/resnet50_caffe\n",
            "06/21 09:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://detectron2/resnet50_caffe\n",
            "06/21 09:13:48 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: conv1.bias\n",
            "\n",
            "06/21 09:13:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://detectron2/resnet50_caffe\n",
            "06/21 09:13:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://detectron2/resnet50_caffe\n",
            "06/21 09:13:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "06/21 09:13:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "06/21 09:13:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmdetection/work_dirs/soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco.\n",
            "06/21 11:34:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [    50/180000]  lr: 9.9098e-04  eta: 350 days, 23:25:39  time: 168.5154  data_time: 0.1042  loss: 2.9510  sup_loss_rpn_cls: 0.1818  sup_loss_rpn_bbox: 0.0090  sup_loss_cls: 0.8552  sup_acc: 98.2422  sup_loss_bbox: 0.0794  unsup_loss_rpn_cls: 0.6887  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 1.1368  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/mmdetection/tools/train.py\", line 143, in <module>\n",
            "    main()\n",
            "  File \"/content/mmdetection/tools/train.py\", line 134, in main\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1721, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 278, in run\n",
            "    self.run_iter(data_batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 301, in run_iter\n",
            "    outputs = self.runner.model.train_step(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\", line 116, in train_step\n",
            "    optim_wrapper.update_params(parsed_losses)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/optim/optimizer/optimizer_wrapper.py\", line 184, in update_params\n",
            "    self.backward(loss)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/optim/optimizer/optimizer_wrapper.py\", line 208, in backward\n",
            "    loss.backward(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 487, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 200, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\", line 264, in apply\n",
            "    def apply(self, *args):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title if you have a saved checkpoint .pth file, then use --resume (path to .pth file or just give auto)\n",
        "#auto will check for the recent epoch checkpoint and continue\n",
        "!python tools/train.py configs/soft_teacher/soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco.py --resume auto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jLCiYQhU-34",
        "outputId": "5dee3259-5cbe-4e00-cba1-7a666d43960b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06/21 05:41:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 1264885612\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.7.0\n",
            "    MMEngine: 0.7.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1264885612\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "06/21 05:41:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "model = dict(\n",
            "    type='SoftTeacher',\n",
            "    detector=dict(\n",
            "        type='FasterRCNN',\n",
            "        data_preprocessor=dict(\n",
            "            type='DetDataPreprocessor',\n",
            "            mean=[103.53, 116.28, 123.675],\n",
            "            std=[1.0, 1.0, 1.0],\n",
            "            bgr_to_rgb=False,\n",
            "            pad_size_divisor=32),\n",
            "        backbone=dict(\n",
            "            type='ResNet',\n",
            "            depth=50,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=False),\n",
            "            norm_eval=True,\n",
            "            style='caffe',\n",
            "            init_cfg=dict(\n",
            "                type='Pretrained',\n",
            "                checkpoint='open-mmlab://detectron2/resnet50_caffe')),\n",
            "        neck=dict(\n",
            "            type='FPN',\n",
            "            in_channels=[256, 512, 1024, 2048],\n",
            "            out_channels=256,\n",
            "            num_outs=5),\n",
            "        rpn_head=dict(\n",
            "            type='RPNHead',\n",
            "            in_channels=256,\n",
            "            feat_channels=256,\n",
            "            anchor_generator=dict(\n",
            "                type='AnchorGenerator',\n",
            "                scales=[8],\n",
            "                ratios=[0.5, 1.0, 2.0],\n",
            "                strides=[4, 8, 16, 32, 64]),\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "        roi_head=dict(\n",
            "            type='StandardRoIHead',\n",
            "            bbox_roi_extractor=dict(\n",
            "                type='SingleRoIExtractor',\n",
            "                roi_layer=dict(\n",
            "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "                out_channels=256,\n",
            "                featmap_strides=[4, 8, 16, 32]),\n",
            "            bbox_head=dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=80,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
            "        train_cfg=dict(\n",
            "            rpn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.7,\n",
            "                    neg_iou_thr=0.3,\n",
            "                    min_pos_iou=0.3,\n",
            "                    match_low_quality=True,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=256,\n",
            "                    pos_fraction=0.5,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=False),\n",
            "                allowed_border=-1,\n",
            "                pos_weight=-1,\n",
            "                debug=False),\n",
            "            rpn_proposal=dict(\n",
            "                nms_pre=2000,\n",
            "                max_per_img=1000,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    min_pos_iou=0.5,\n",
            "                    match_low_quality=False,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=True),\n",
            "                pos_weight=-1,\n",
            "                debug=False)),\n",
            "        test_cfg=dict(\n",
            "            rpn=dict(\n",
            "                nms_pre=1000,\n",
            "                max_per_img=1000,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                score_thr=0.05,\n",
            "                nms=dict(type='nms', iou_threshold=0.5),\n",
            "                max_per_img=100))),\n",
            "    data_preprocessor=dict(\n",
            "        type='MultiBranchDataPreprocessor',\n",
            "        data_preprocessor=dict(\n",
            "            type='DetDataPreprocessor',\n",
            "            mean=[103.53, 116.28, 123.675],\n",
            "            std=[1.0, 1.0, 1.0],\n",
            "            bgr_to_rgb=False,\n",
            "            pad_size_divisor=32)),\n",
            "    semi_train_cfg=dict(\n",
            "        freeze_teacher=True,\n",
            "        sup_weight=1.0,\n",
            "        unsup_weight=4.0,\n",
            "        pseudo_label_initial_score_thr=0.5,\n",
            "        rpn_pseudo_thr=0.9,\n",
            "        cls_pseudo_thr=0.9,\n",
            "        reg_pseudo_thr=0.02,\n",
            "        jitter_times=10,\n",
            "        jitter_scale=0.06,\n",
            "        min_pseudo_bbox_wh=(0.01, 0.01)),\n",
            "    semi_test_cfg=dict(predict_on='teacher'))\n",
            "default_scope = 'mmdet'\n",
            "default_hooks = dict(\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=50),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(\n",
            "        type='CheckpointHook',\n",
            "        interval=10000,\n",
            "        by_epoch=False,\n",
            "        max_keep_ckpts=2),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    visualization=dict(type='DetVisualizationHook'))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "vis_backends = [dict(type='LocalVisBackend')]\n",
            "visualizer = dict(\n",
            "    type='DetLocalVisualizer',\n",
            "    vis_backends=[dict(type='LocalVisBackend')],\n",
            "    name='visualizer')\n",
            "log_processor = dict(type='LogProcessor', window_size=50, by_epoch=False)\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume = True\n",
            "dataset_type = 'CocoDataset'\n",
            "data_root = 'data/coco/'\n",
            "backend_args = None\n",
            "color_space = [[{\n",
            "    'type': 'ColorTransform'\n",
            "}], [{\n",
            "    'type': 'AutoContrast'\n",
            "}], [{\n",
            "    'type': 'Equalize'\n",
            "}], [{\n",
            "    'type': 'Sharpness'\n",
            "}], [{\n",
            "    'type': 'Posterize'\n",
            "}], [{\n",
            "    'type': 'Solarize'\n",
            "}], [{\n",
            "    'type': 'Color'\n",
            "}], [{\n",
            "    'type': 'Contrast'\n",
            "}], [{\n",
            "    'type': 'Brightness'\n",
            "}]]\n",
            "geometric = [[{\n",
            "    'type': 'Rotate'\n",
            "}], [{\n",
            "    'type': 'ShearX'\n",
            "}], [{\n",
            "    'type': 'ShearY'\n",
            "}], [{\n",
            "    'type': 'TranslateX'\n",
            "}], [{\n",
            "    'type': 'TranslateY'\n",
            "}]]\n",
            "scale = [(1333, 400), (1333, 1200)]\n",
            "branch_field = ['sup', 'unsup_teacher', 'unsup_student']\n",
            "sup_pipeline = [\n",
            "    dict(type='LoadImageFromFile', backend_args=None),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        type='RandomResize',\n",
            "        scale=[(1333, 400), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='RandomFlip', prob=0.5),\n",
            "    dict(\n",
            "        type='RandAugment',\n",
            "        aug_space=[[{\n",
            "            'type': 'ColorTransform'\n",
            "        }], [{\n",
            "            'type': 'AutoContrast'\n",
            "        }], [{\n",
            "            'type': 'Equalize'\n",
            "        }], [{\n",
            "            'type': 'Sharpness'\n",
            "        }], [{\n",
            "            'type': 'Posterize'\n",
            "        }], [{\n",
            "            'type': 'Solarize'\n",
            "        }], [{\n",
            "            'type': 'Color'\n",
            "        }], [{\n",
            "            'type': 'Contrast'\n",
            "        }], [{\n",
            "            'type': 'Brightness'\n",
            "        }]],\n",
            "        aug_num=1),\n",
            "    dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),\n",
            "    dict(\n",
            "        type='MultiBranch',\n",
            "        branch_field=['sup', 'unsup_teacher', 'unsup_student'],\n",
            "        sup=dict(type='PackDetInputs'))\n",
            "]\n",
            "weak_pipeline = [\n",
            "    dict(\n",
            "        type='RandomResize',\n",
            "        scale=[(1333, 400), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='RandomFlip', prob=0.5),\n",
            "    dict(\n",
            "        type='PackDetInputs',\n",
            "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                   'scale_factor', 'flip', 'flip_direction',\n",
            "                   'homography_matrix'))\n",
            "]\n",
            "strong_pipeline = [\n",
            "    dict(\n",
            "        type='RandomResize',\n",
            "        scale=[(1333, 400), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='RandomFlip', prob=0.5),\n",
            "    dict(\n",
            "        type='RandomOrder',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RandAugment',\n",
            "                aug_space=[[{\n",
            "                    'type': 'ColorTransform'\n",
            "                }], [{\n",
            "                    'type': 'AutoContrast'\n",
            "                }], [{\n",
            "                    'type': 'Equalize'\n",
            "                }], [{\n",
            "                    'type': 'Sharpness'\n",
            "                }], [{\n",
            "                    'type': 'Posterize'\n",
            "                }], [{\n",
            "                    'type': 'Solarize'\n",
            "                }], [{\n",
            "                    'type': 'Color'\n",
            "                }], [{\n",
            "                    'type': 'Contrast'\n",
            "                }], [{\n",
            "                    'type': 'Brightness'\n",
            "                }]],\n",
            "                aug_num=1),\n",
            "            dict(\n",
            "                type='RandAugment',\n",
            "                aug_space=[[{\n",
            "                    'type': 'Rotate'\n",
            "                }], [{\n",
            "                    'type': 'ShearX'\n",
            "                }], [{\n",
            "                    'type': 'ShearY'\n",
            "                }], [{\n",
            "                    'type': 'TranslateX'\n",
            "                }], [{\n",
            "                    'type': 'TranslateY'\n",
            "                }]],\n",
            "                aug_num=1)\n",
            "        ]),\n",
            "    dict(type='RandomErasing', n_patches=(1, 5), ratio=(0, 0.2)),\n",
            "    dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),\n",
            "    dict(\n",
            "        type='PackDetInputs',\n",
            "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                   'scale_factor', 'flip', 'flip_direction',\n",
            "                   'homography_matrix'))\n",
            "]\n",
            "unsup_pipeline = [\n",
            "    dict(type='LoadImageFromFile', backend_args=None),\n",
            "    dict(type='LoadEmptyAnnotations'),\n",
            "    dict(\n",
            "        type='MultiBranch',\n",
            "        branch_field=['sup', 'unsup_teacher', 'unsup_student'],\n",
            "        unsup_teacher=[\n",
            "            dict(\n",
            "                type='RandomResize',\n",
            "                scale=[(1333, 400), (1333, 1200)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='RandomFlip', prob=0.5),\n",
            "            dict(\n",
            "                type='PackDetInputs',\n",
            "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                           'scale_factor', 'flip', 'flip_direction',\n",
            "                           'homography_matrix'))\n",
            "        ],\n",
            "        unsup_student=[\n",
            "            dict(\n",
            "                type='RandomResize',\n",
            "                scale=[(1333, 400), (1333, 1200)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='RandomFlip', prob=0.5),\n",
            "            dict(\n",
            "                type='RandomOrder',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RandAugment',\n",
            "                        aug_space=[[{\n",
            "                            'type': 'ColorTransform'\n",
            "                        }], [{\n",
            "                            'type': 'AutoContrast'\n",
            "                        }], [{\n",
            "                            'type': 'Equalize'\n",
            "                        }], [{\n",
            "                            'type': 'Sharpness'\n",
            "                        }], [{\n",
            "                            'type': 'Posterize'\n",
            "                        }], [{\n",
            "                            'type': 'Solarize'\n",
            "                        }], [{\n",
            "                            'type': 'Color'\n",
            "                        }], [{\n",
            "                            'type': 'Contrast'\n",
            "                        }], [{\n",
            "                            'type': 'Brightness'\n",
            "                        }]],\n",
            "                        aug_num=1),\n",
            "                    dict(\n",
            "                        type='RandAugment',\n",
            "                        aug_space=[[{\n",
            "                            'type': 'Rotate'\n",
            "                        }], [{\n",
            "                            'type': 'ShearX'\n",
            "                        }], [{\n",
            "                            'type': 'ShearY'\n",
            "                        }], [{\n",
            "                            'type': 'TranslateX'\n",
            "                        }], [{\n",
            "                            'type': 'TranslateY'\n",
            "                        }]],\n",
            "                        aug_num=1)\n",
            "                ]),\n",
            "            dict(type='RandomErasing', n_patches=(1, 5), ratio=(0, 0.2)),\n",
            "            dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),\n",
            "            dict(\n",
            "                type='PackDetInputs',\n",
            "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                           'scale_factor', 'flip', 'flip_direction',\n",
            "                           'homography_matrix'))\n",
            "        ])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile', backend_args=None),\n",
            "    dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
            "    dict(\n",
            "        type='PackDetInputs',\n",
            "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                   'scale_factor'))\n",
            "]\n",
            "batch_size = 5\n",
            "num_workers = 5\n",
            "labeled_dataset = dict(\n",
            "    type='CocoDataset',\n",
            "    data_root='data/coco/',\n",
            "    ann_file='annotations/coco_annotations.json',\n",
            "    data_prefix=dict(img='train/'),\n",
            "    filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile', backend_args=None),\n",
            "        dict(type='LoadAnnotations', with_bbox=True),\n",
            "        dict(\n",
            "            type='RandomResize',\n",
            "            scale=[(1333, 400), (1333, 1200)],\n",
            "            keep_ratio=True),\n",
            "        dict(type='RandomFlip', prob=0.5),\n",
            "        dict(\n",
            "            type='RandAugment',\n",
            "            aug_space=[[{\n",
            "                'type': 'ColorTransform'\n",
            "            }], [{\n",
            "                'type': 'AutoContrast'\n",
            "            }], [{\n",
            "                'type': 'Equalize'\n",
            "            }], [{\n",
            "                'type': 'Sharpness'\n",
            "            }], [{\n",
            "                'type': 'Posterize'\n",
            "            }], [{\n",
            "                'type': 'Solarize'\n",
            "            }], [{\n",
            "                'type': 'Color'\n",
            "            }], [{\n",
            "                'type': 'Contrast'\n",
            "            }], [{\n",
            "                'type': 'Brightness'\n",
            "            }]],\n",
            "            aug_num=1),\n",
            "        dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),\n",
            "        dict(\n",
            "            type='MultiBranch',\n",
            "            branch_field=['sup', 'unsup_teacher', 'unsup_student'],\n",
            "            sup=dict(type='PackDetInputs'))\n",
            "    ],\n",
            "    backend_args=None)\n",
            "unlabeled_dataset = dict(\n",
            "    type='CocoDataset',\n",
            "    data_root='data/coco/',\n",
            "    ann_file='annotations/val_coco_annotations.json',\n",
            "    data_prefix=dict(img='val/'),\n",
            "    filter_cfg=dict(filter_empty_gt=False),\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile', backend_args=None),\n",
            "        dict(type='LoadEmptyAnnotations'),\n",
            "        dict(\n",
            "            type='MultiBranch',\n",
            "            branch_field=['sup', 'unsup_teacher', 'unsup_student'],\n",
            "            unsup_teacher=[\n",
            "                dict(\n",
            "                    type='RandomResize',\n",
            "                    scale=[(1333, 400), (1333, 1200)],\n",
            "                    keep_ratio=True),\n",
            "                dict(type='RandomFlip', prob=0.5),\n",
            "                dict(\n",
            "                    type='PackDetInputs',\n",
            "                    meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                               'scale_factor', 'flip', 'flip_direction',\n",
            "                               'homography_matrix'))\n",
            "            ],\n",
            "            unsup_student=[\n",
            "                dict(\n",
            "                    type='RandomResize',\n",
            "                    scale=[(1333, 400), (1333, 1200)],\n",
            "                    keep_ratio=True),\n",
            "                dict(type='RandomFlip', prob=0.5),\n",
            "                dict(\n",
            "                    type='RandomOrder',\n",
            "                    transforms=[\n",
            "                        dict(\n",
            "                            type='RandAugment',\n",
            "                            aug_space=[[{\n",
            "                                'type': 'ColorTransform'\n",
            "                            }], [{\n",
            "                                'type': 'AutoContrast'\n",
            "                            }], [{\n",
            "                                'type': 'Equalize'\n",
            "                            }], [{\n",
            "                                'type': 'Sharpness'\n",
            "                            }], [{\n",
            "                                'type': 'Posterize'\n",
            "                            }], [{\n",
            "                                'type': 'Solarize'\n",
            "                            }], [{\n",
            "                                'type': 'Color'\n",
            "                            }], [{\n",
            "                                'type': 'Contrast'\n",
            "                            }], [{\n",
            "                                'type': 'Brightness'\n",
            "                            }]],\n",
            "                            aug_num=1),\n",
            "                        dict(\n",
            "                            type='RandAugment',\n",
            "                            aug_space=[[{\n",
            "                                'type': 'Rotate'\n",
            "                            }], [{\n",
            "                                'type': 'ShearX'\n",
            "                            }], [{\n",
            "                                'type': 'ShearY'\n",
            "                            }], [{\n",
            "                                'type': 'TranslateX'\n",
            "                            }], [{\n",
            "                                'type': 'TranslateY'\n",
            "                            }]],\n",
            "                            aug_num=1)\n",
            "                    ]),\n",
            "                dict(type='RandomErasing', n_patches=(1, 5), ratio=(0, 0.2)),\n",
            "                dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),\n",
            "                dict(\n",
            "                    type='PackDetInputs',\n",
            "                    meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                               'scale_factor', 'flip', 'flip_direction',\n",
            "                               'homography_matrix'))\n",
            "            ])\n",
            "    ],\n",
            "    backend_args=None)\n",
            "train_dataloader = dict(\n",
            "    batch_size=5,\n",
            "    num_workers=5,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(\n",
            "        type='GroupMultiSourceSampler', batch_size=5, source_ratio=[1, 4]),\n",
            "    dataset=dict(\n",
            "        type='ConcatDataset',\n",
            "        datasets=[\n",
            "            dict(\n",
            "                type='CocoDataset',\n",
            "                data_root='data/coco/',\n",
            "                ann_file='annotations/coco_annotations.json',\n",
            "                data_prefix=dict(img='train/'),\n",
            "                filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile', backend_args=None),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                    dict(\n",
            "                        type='RandomResize',\n",
            "                        scale=[(1333, 400), (1333, 1200)],\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', prob=0.5),\n",
            "                    dict(\n",
            "                        type='RandAugment',\n",
            "                        aug_space=[[{\n",
            "                            'type': 'ColorTransform'\n",
            "                        }], [{\n",
            "                            'type': 'AutoContrast'\n",
            "                        }], [{\n",
            "                            'type': 'Equalize'\n",
            "                        }], [{\n",
            "                            'type': 'Sharpness'\n",
            "                        }], [{\n",
            "                            'type': 'Posterize'\n",
            "                        }], [{\n",
            "                            'type': 'Solarize'\n",
            "                        }], [{\n",
            "                            'type': 'Color'\n",
            "                        }], [{\n",
            "                            'type': 'Contrast'\n",
            "                        }], [{\n",
            "                            'type': 'Brightness'\n",
            "                        }]],\n",
            "                        aug_num=1),\n",
            "                    dict(\n",
            "                        type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),\n",
            "                    dict(\n",
            "                        type='MultiBranch',\n",
            "                        branch_field=['sup', 'unsup_teacher', 'unsup_student'],\n",
            "                        sup=dict(type='PackDetInputs'))\n",
            "                ],\n",
            "                backend_args=None),\n",
            "            dict(\n",
            "                type='CocoDataset',\n",
            "                data_root='data/coco/',\n",
            "                ann_file='annotations/val_coco_annotations.json',\n",
            "                data_prefix=dict(img='val/'),\n",
            "                filter_cfg=dict(filter_empty_gt=False),\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile', backend_args=None),\n",
            "                    dict(type='LoadEmptyAnnotations'),\n",
            "                    dict(\n",
            "                        type='MultiBranch',\n",
            "                        branch_field=['sup', 'unsup_teacher', 'unsup_student'],\n",
            "                        unsup_teacher=[\n",
            "                            dict(\n",
            "                                type='RandomResize',\n",
            "                                scale=[(1333, 400), (1333, 1200)],\n",
            "                                keep_ratio=True),\n",
            "                            dict(type='RandomFlip', prob=0.5),\n",
            "                            dict(\n",
            "                                type='PackDetInputs',\n",
            "                                meta_keys=('img_id', 'img_path', 'ori_shape',\n",
            "                                           'img_shape', 'scale_factor', 'flip',\n",
            "                                           'flip_direction',\n",
            "                                           'homography_matrix'))\n",
            "                        ],\n",
            "                        unsup_student=[\n",
            "                            dict(\n",
            "                                type='RandomResize',\n",
            "                                scale=[(1333, 400), (1333, 1200)],\n",
            "                                keep_ratio=True),\n",
            "                            dict(type='RandomFlip', prob=0.5),\n",
            "                            dict(\n",
            "                                type='RandomOrder',\n",
            "                                transforms=[\n",
            "                                    dict(\n",
            "                                        type='RandAugment',\n",
            "                                        aug_space=[[{\n",
            "                                            'type': 'ColorTransform'\n",
            "                                        }], [{\n",
            "                                            'type': 'AutoContrast'\n",
            "                                        }], [{\n",
            "                                            'type': 'Equalize'\n",
            "                                        }], [{\n",
            "                                            'type': 'Sharpness'\n",
            "                                        }], [{\n",
            "                                            'type': 'Posterize'\n",
            "                                        }], [{\n",
            "                                            'type': 'Solarize'\n",
            "                                        }], [{\n",
            "                                            'type': 'Color'\n",
            "                                        }], [{\n",
            "                                            'type': 'Contrast'\n",
            "                                        }], [{\n",
            "                                            'type': 'Brightness'\n",
            "                                        }]],\n",
            "                                        aug_num=1),\n",
            "                                    dict(\n",
            "                                        type='RandAugment',\n",
            "                                        aug_space=[[{\n",
            "                                            'type': 'Rotate'\n",
            "                                        }], [{\n",
            "                                            'type': 'ShearX'\n",
            "                                        }], [{\n",
            "                                            'type': 'ShearY'\n",
            "                                        }], [{\n",
            "                                            'type': 'TranslateX'\n",
            "                                        }], [{\n",
            "                                            'type': 'TranslateY'\n",
            "                                        }]],\n",
            "                                        aug_num=1)\n",
            "                                ]),\n",
            "                            dict(\n",
            "                                type='RandomErasing',\n",
            "                                n_patches=(1, 5),\n",
            "                                ratio=(0, 0.2)),\n",
            "                            dict(\n",
            "                                type='FilterAnnotations',\n",
            "                                min_gt_bbox_wh=(0.01, 0.01)),\n",
            "                            dict(\n",
            "                                type='PackDetInputs',\n",
            "                                meta_keys=('img_id', 'img_path', 'ori_shape',\n",
            "                                           'img_shape', 'scale_factor', 'flip',\n",
            "                                           'flip_direction',\n",
            "                                           'homography_matrix'))\n",
            "                        ])\n",
            "                ],\n",
            "                backend_args=None)\n",
            "        ]))\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    drop_last=False,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='CocoDataset',\n",
            "        data_root='data/coco/',\n",
            "        ann_file='annotations/val_coco_annotations.json',\n",
            "        data_prefix=dict(img='val2017/'),\n",
            "        test_mode=True,\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile', backend_args=None),\n",
            "            dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
            "            dict(\n",
            "                type='PackDetInputs',\n",
            "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                           'scale_factor'))\n",
            "        ],\n",
            "        backend_args=None))\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    drop_last=False,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='CocoDataset',\n",
            "        data_root='data/coco/',\n",
            "        ann_file='annotations/val_coco_annotations.json',\n",
            "        data_prefix=dict(img='val2017/'),\n",
            "        test_mode=True,\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile', backend_args=None),\n",
            "            dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
            "            dict(\n",
            "                type='PackDetInputs',\n",
            "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                           'scale_factor'))\n",
            "        ],\n",
            "        backend_args=None))\n",
            "val_evaluator = dict(\n",
            "    type='CocoMetric',\n",
            "    ann_file='data/coco/annotations/val_coco_annotations.json',\n",
            "    metric='bbox',\n",
            "    format_only=False,\n",
            "    backend_args=None)\n",
            "test_evaluator = dict(\n",
            "    type='CocoMetric',\n",
            "    ann_file='data/coco/annotations/val_coco_annotations.json',\n",
            "    metric='bbox',\n",
            "    format_only=False,\n",
            "    backend_args=None)\n",
            "detector = dict(\n",
            "    type='FasterRCNN',\n",
            "    data_preprocessor=dict(\n",
            "        type='DetDataPreprocessor',\n",
            "        mean=[103.53, 116.28, 123.675],\n",
            "        std=[1.0, 1.0, 1.0],\n",
            "        bgr_to_rgb=False,\n",
            "        pad_size_divisor=32),\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=False),\n",
            "        norm_eval=True,\n",
            "        style='caffe',\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained',\n",
            "            checkpoint='open-mmlab://detectron2/resnet50_caffe')),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='StandardRoIHead',\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        bbox_head=dict(\n",
            "            type='Shared2FCBBoxHead',\n",
            "            in_channels=256,\n",
            "            fc_out_channels=1024,\n",
            "            roi_feat_size=7,\n",
            "            num_classes=80,\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "            reg_class_agnostic=False,\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
            "    train_cfg=dict(\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.3,\n",
            "                min_pos_iou=0.3,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=False),\n",
            "            allowed_border=-1,\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        rpn_proposal=dict(\n",
            "            nms_pre=2000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)),\n",
            "    test_cfg=dict(\n",
            "        rpn=dict(\n",
            "            nms_pre=1000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            score_thr=0.05,\n",
            "            nms=dict(type='nms', iou_threshold=0.5),\n",
            "            max_per_img=100)))\n",
            "train_cfg = dict(\n",
            "    type='IterBasedTrainLoop', max_iters=180000, val_interval=5000)\n",
            "val_cfg = dict(type='TeacherStudentValLoop')\n",
            "test_cfg = dict(type='TestLoop')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        type='LinearLR', start_factor=0.001, by_epoch=False, begin=0, end=500),\n",
            "    dict(\n",
            "        type='MultiStepLR',\n",
            "        begin=0,\n",
            "        end=180000,\n",
            "        by_epoch=False,\n",
            "        milestones=[120000, 160000],\n",
            "        gamma=0.1)\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    type='OptimWrapper',\n",
            "    optimizer=dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001))\n",
            "custom_hooks = [dict(type='MeanTeacherHook')]\n",
            "launcher = 'none'\n",
            "work_dir = './work_dirs/soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco'\n",
            "\n",
            "06/21 05:41:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "06/21 05:41:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) MeanTeacherHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) MeanTeacherHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loading annotations into memory...\n",
            "Done (t=0.22s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "06/21 05:41:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://detectron2/resnet50_caffe\n",
            "06/21 05:41:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://detectron2/resnet50_caffe\n",
            "06/21 05:41:38 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: conv1.bias\n",
            "\n",
            "06/21 05:41:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://detectron2/resnet50_caffe\n",
            "06/21 05:41:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://detectron2/resnet50_caffe\n",
            "Did not find last_checkpoint to be resumed.\n",
            "06/21 05:41:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Auto resumed from the latest checkpoint None.\n",
            "06/21 05:41:38 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "06/21 05:41:38 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "06/21 05:41:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmdetection/work_dirs/soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco.\n",
            "06/21 05:42:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [    50/180000]  lr: 9.9098e-04  eta: 2 days, 17:21:50  time: 1.3076  data_time: 0.0248  memory: 4504  loss: 2.6249  sup_loss_rpn_cls: 0.1815  sup_loss_rpn_bbox: 0.0116  sup_loss_cls: 0.7555  sup_acc: 96.4844  sup_loss_bbox: 0.0725  unsup_loss_rpn_cls: 0.6638  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.9400  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:43:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   100/180000]  lr: 1.9920e-03  eta: 2 days, 17:22:57  time: 1.3091  data_time: 0.0246  memory: 4504  loss: 0.4944  sup_loss_rpn_cls: 0.0325  sup_loss_rpn_bbox: 0.0108  sup_loss_cls: 0.3005  sup_acc: 98.2422  sup_loss_bbox: 0.1109  unsup_loss_rpn_cls: 0.0270  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0127  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:44:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   150/180000]  lr: 2.9930e-03  eta: 2 days, 17:56:18  time: 1.3428  data_time: 0.0245  memory: 4504  loss: 0.3445  sup_loss_rpn_cls: 0.0312  sup_loss_rpn_bbox: 0.0090  sup_loss_cls: 0.1616  sup_acc: 96.8750  sup_loss_bbox: 0.1169  unsup_loss_rpn_cls: 0.0102  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0156  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   200/180000]  lr: 3.9940e-03  eta: 2 days, 18:37:04  time: 1.3757  data_time: 0.0262  memory: 4504  loss: 0.3487  sup_loss_rpn_cls: 0.0257  sup_loss_rpn_bbox: 0.0088  sup_loss_cls: 0.1626  sup_acc: 96.4844  sup_loss_bbox: 0.1256  unsup_loss_rpn_cls: 0.0097  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0164  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:47:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   250/180000]  lr: 4.9950e-03  eta: 2 days, 18:55:26  time: 1.3664  data_time: 0.0249  memory: 4504  loss: 0.3279  sup_loss_rpn_cls: 0.0234  sup_loss_rpn_bbox: 0.0077  sup_loss_cls: 0.1533  sup_acc: 97.4609  sup_loss_bbox: 0.1170  unsup_loss_rpn_cls: 0.0084  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0180  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:48:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   300/180000]  lr: 5.9960e-03  eta: 2 days, 19:03:22  time: 1.3585  data_time: 0.0253  memory: 4504  loss: 0.3058  sup_loss_rpn_cls: 0.0215  sup_loss_rpn_bbox: 0.0081  sup_loss_cls: 0.1412  sup_acc: 96.2891  sup_loss_bbox: 0.1154  unsup_loss_rpn_cls: 0.0060  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0137  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:49:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   350/180000]  lr: 6.9970e-03  eta: 2 days, 19:15:16  time: 1.3738  data_time: 0.0255  memory: 4504  loss: 0.3066  sup_loss_rpn_cls: 0.0235  sup_loss_rpn_bbox: 0.0094  sup_loss_cls: 0.1397  sup_acc: 97.6562  sup_loss_bbox: 0.1143  unsup_loss_rpn_cls: 0.0062  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0135  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:50:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   400/180000]  lr: 7.9980e-03  eta: 2 days, 19:20:21  time: 1.3643  data_time: 0.0245  memory: 4504  loss: 0.2820  sup_loss_rpn_cls: 0.0202  sup_loss_rpn_bbox: 0.0079  sup_loss_cls: 0.1298  sup_acc: 96.6797  sup_loss_bbox: 0.1078  unsup_loss_rpn_cls: 0.0046  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0118  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:51:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   450/180000]  lr: 8.9990e-03  eta: 2 days, 19:26:21  time: 1.3712  data_time: 0.0244  memory: 4504  loss: 0.2956  sup_loss_rpn_cls: 0.0195  sup_loss_rpn_bbox: 0.0089  sup_loss_cls: 0.1404  sup_acc: 97.6562  sup_loss_bbox: 0.1040  unsup_loss_rpn_cls: 0.0087  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0140  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:52:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   500/180000]  lr: 1.0000e-02  eta: 2 days, 19:29:31  time: 1.3666  data_time: 0.0247  memory: 4504  loss: 0.2881  sup_loss_rpn_cls: 0.0191  sup_loss_rpn_bbox: 0.0077  sup_loss_cls: 0.1313  sup_acc: 97.4609  sup_loss_bbox: 0.1109  unsup_loss_rpn_cls: 0.0056  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0134  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:54:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   550/180000]  lr: 1.0000e-02  eta: 2 days, 19:39:15  time: 1.3935  data_time: 0.0263  memory: 4504  loss: 0.2926  sup_loss_rpn_cls: 0.0152  sup_loss_rpn_bbox: 0.0067  sup_loss_cls: 0.1413  sup_acc: 96.2891  sup_loss_bbox: 0.1113  unsup_loss_rpn_cls: 0.0052  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0130  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:55:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   600/180000]  lr: 1.0000e-02  eta: 2 days, 19:44:47  time: 1.3840  data_time: 0.0259  memory: 4504  loss: 0.2870  sup_loss_rpn_cls: 0.0177  sup_loss_rpn_bbox: 0.0075  sup_loss_cls: 0.1326  sup_acc: 97.4609  sup_loss_bbox: 0.1017  unsup_loss_rpn_cls: 0.0092  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0184  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:56:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   650/180000]  lr: 1.0000e-02  eta: 2 days, 19:50:37  time: 1.3897  data_time: 0.0244  memory: 4504  loss: 0.2948  sup_loss_rpn_cls: 0.0179  sup_loss_rpn_bbox: 0.0065  sup_loss_cls: 0.1359  sup_acc: 97.8516  sup_loss_bbox: 0.1100  unsup_loss_rpn_cls: 0.0072  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0173  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:57:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   700/180000]  lr: 1.0000e-02  eta: 2 days, 19:53:32  time: 1.3808  data_time: 0.0243  memory: 4504  loss: 0.2893  sup_loss_rpn_cls: 0.0168  sup_loss_rpn_bbox: 0.0077  sup_loss_cls: 0.1424  sup_acc: 95.8984  sup_loss_bbox: 0.0990  unsup_loss_rpn_cls: 0.0068  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0165  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:58:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   750/180000]  lr: 1.0000e-02  eta: 2 days, 20:01:11  time: 1.4072  data_time: 0.0270  memory: 4504  loss: 0.2643  sup_loss_rpn_cls: 0.0129  sup_loss_rpn_bbox: 0.0074  sup_loss_cls: 0.1249  sup_acc: 95.8984  sup_loss_bbox: 0.1001  unsup_loss_rpn_cls: 0.0055  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0133  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 05:59:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   800/180000]  lr: 1.0000e-02  eta: 2 days, 20:04:10  time: 1.3882  data_time: 0.0248  memory: 4504  loss: 0.2457  sup_loss_rpn_cls: 0.0157  sup_loss_rpn_bbox: 0.0069  sup_loss_cls: 0.1121  sup_acc: 96.8750  sup_loss_bbox: 0.0921  unsup_loss_rpn_cls: 0.0061  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0128  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:01:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   850/180000]  lr: 1.0000e-02  eta: 2 days, 20:06:42  time: 1.3884  data_time: 0.0249  memory: 4504  loss: 0.2742  sup_loss_rpn_cls: 0.0139  sup_loss_rpn_bbox: 0.0095  sup_loss_cls: 0.1297  sup_acc: 97.0703  sup_loss_bbox: 0.1025  unsup_loss_rpn_cls: 0.0055  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0131  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:02:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   900/180000]  lr: 1.0000e-02  eta: 2 days, 20:09:01  time: 1.3895  data_time: 0.0265  memory: 4504  loss: 0.2346  sup_loss_rpn_cls: 0.0111  sup_loss_rpn_bbox: 0.0068  sup_loss_cls: 0.1021  sup_acc: 97.0703  sup_loss_bbox: 0.1006  unsup_loss_rpn_cls: 0.0041  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0100  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:03:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   950/180000]  lr: 1.0000e-02  eta: 2 days, 20:09:14  time: 1.3786  data_time: 0.0253  memory: 4504  loss: 0.2425  sup_loss_rpn_cls: 0.0130  sup_loss_rpn_bbox: 0.0070  sup_loss_cls: 0.1107  sup_acc: 97.8516  sup_loss_bbox: 0.0979  unsup_loss_rpn_cls: 0.0046  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0092  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:04:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco_20230621_054100\n",
            "06/21 06:04:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1000/180000]  lr: 1.0000e-02  eta: 2 days, 20:08:55  time: 1.3759  data_time: 0.0253  memory: 4504  loss: 0.2075  sup_loss_rpn_cls: 0.0100  sup_loss_rpn_bbox: 0.0078  sup_loss_cls: 0.0972  sup_acc: 97.2656  sup_loss_bbox: 0.0824  unsup_loss_rpn_cls: 0.0039  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0062  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:05:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1050/180000]  lr: 1.0000e-02  eta: 2 days, 20:10:00  time: 1.3863  data_time: 0.0250  memory: 4504  loss: 0.2474  sup_loss_rpn_cls: 0.0103  sup_loss_rpn_bbox: 0.0071  sup_loss_cls: 0.1186  sup_acc: 97.2656  sup_loss_bbox: 0.0933  unsup_loss_rpn_cls: 0.0044  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0137  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:06:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1100/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:24  time: 1.4048  data_time: 0.0274  memory: 4504  loss: 0.2374  sup_loss_rpn_cls: 0.0127  sup_loss_rpn_bbox: 0.0073  sup_loss_cls: 0.1107  sup_acc: 98.6328  sup_loss_bbox: 0.0849  unsup_loss_rpn_cls: 0.0079  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0139  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:07:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1150/180000]  lr: 1.0000e-02  eta: 2 days, 20:14:23  time: 1.3893  data_time: 0.0245  memory: 4504  loss: 0.2372  sup_loss_rpn_cls: 0.0106  sup_loss_rpn_bbox: 0.0073  sup_loss_cls: 0.1104  sup_acc: 98.4375  sup_loss_bbox: 0.0887  unsup_loss_rpn_cls: 0.0056  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0147  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1200/180000]  lr: 1.0000e-02  eta: 2 days, 20:15:18  time: 1.3901  data_time: 0.0264  memory: 4504  loss: 0.2217  sup_loss_rpn_cls: 0.0132  sup_loss_rpn_bbox: 0.0073  sup_loss_cls: 0.0986  sup_acc: 97.2656  sup_loss_bbox: 0.0866  unsup_loss_rpn_cls: 0.0042  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0118  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:10:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1250/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:50  time: 1.3717  data_time: 0.0247  memory: 4504  loss: 0.2058  sup_loss_rpn_cls: 0.0062  sup_loss_rpn_bbox: 0.0053  sup_loss_cls: 0.0950  sup_acc: 96.2891  sup_loss_bbox: 0.0872  unsup_loss_rpn_cls: 0.0034  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0087  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:11:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1300/180000]  lr: 1.0000e-02  eta: 2 days, 20:14:00  time: 1.3855  data_time: 0.0253  memory: 4504  loss: 0.2136  sup_loss_rpn_cls: 0.0102  sup_loss_rpn_bbox: 0.0065  sup_loss_cls: 0.0960  sup_acc: 98.0469  sup_loss_bbox: 0.0846  unsup_loss_rpn_cls: 0.0039  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0124  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:12:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1350/180000]  lr: 1.0000e-02  eta: 2 days, 20:14:49  time: 1.3924  data_time: 0.0257  memory: 4504  loss: 0.2152  sup_loss_rpn_cls: 0.0119  sup_loss_rpn_bbox: 0.0096  sup_loss_cls: 0.0923  sup_acc: 97.4609  sup_loss_bbox: 0.0845  unsup_loss_rpn_cls: 0.0047  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0122  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:13:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1400/180000]  lr: 1.0000e-02  eta: 2 days, 20:14:54  time: 1.3868  data_time: 0.0254  memory: 4504  loss: 0.1792  sup_loss_rpn_cls: 0.0065  sup_loss_rpn_bbox: 0.0055  sup_loss_cls: 0.0794  sup_acc: 97.8516  sup_loss_bbox: 0.0765  unsup_loss_rpn_cls: 0.0036  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0076  unsup_acc: 99.9512  unsup_loss_bbox: 0.0000\n",
            "06/21 06:14:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco_20230621_054100\n",
            "06/21 06:14:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1450/180000]  lr: 1.0000e-02  eta: 2 days, 20:15:02  time: 1.3881  data_time: 0.0262  memory: 4504  loss: 0.2173  sup_loss_rpn_cls: 0.0096  sup_loss_rpn_bbox: 0.0083  sup_loss_cls: 0.0987  sup_acc: 97.6562  sup_loss_bbox: 0.0836  unsup_loss_rpn_cls: 0.0054  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0116  unsup_acc: 99.9023  unsup_loss_bbox: 0.0000\n",
            "06/21 06:16:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1500/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:31  time: 1.3723  data_time: 0.0254  memory: 4504  loss: 0.1945  sup_loss_rpn_cls: 0.0095  sup_loss_rpn_bbox: 0.0067  sup_loss_cls: 0.0837  sup_acc: 99.2188  sup_loss_bbox: 0.0805  unsup_loss_rpn_cls: 0.0034  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0107  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:17:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1550/180000]  lr: 1.0000e-02  eta: 2 days, 20:12:46  time: 1.3802  data_time: 0.0246  memory: 4504  loss: 0.1844  sup_loss_rpn_cls: 0.0082  sup_loss_rpn_bbox: 0.0068  sup_loss_cls: 0.0798  sup_acc: 99.0234  sup_loss_bbox: 0.0751  unsup_loss_rpn_cls: 0.0041  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0104  unsup_acc: 99.7070  unsup_loss_bbox: 0.0000\n",
            "06/21 06:18:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1600/180000]  lr: 1.0000e-02  eta: 2 days, 20:12:20  time: 1.3837  data_time: 0.0249  memory: 4504  loss: 0.1833  sup_loss_rpn_cls: 0.0087  sup_loss_rpn_bbox: 0.0061  sup_loss_cls: 0.0775  sup_acc: 99.6094  sup_loss_bbox: 0.0791  unsup_loss_rpn_cls: 0.0029  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0092  unsup_acc: 99.2676  unsup_loss_bbox: 0.0000\n",
            "06/21 06:19:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1650/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:27  time: 1.4016  data_time: 0.0273  memory: 4504  loss: 0.1858  sup_loss_rpn_cls: 0.0071  sup_loss_rpn_bbox: 0.0062  sup_loss_cls: 0.0803  sup_acc: 97.8516  sup_loss_bbox: 0.0792  unsup_loss_rpn_cls: 0.0036  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0093  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:20:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1700/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:15  time: 1.3880  data_time: 0.0248  memory: 4504  loss: 0.1678  sup_loss_rpn_cls: 0.0056  sup_loss_rpn_bbox: 0.0070  sup_loss_cls: 0.0697  sup_acc: 97.2656  sup_loss_bbox: 0.0772  unsup_loss_rpn_cls: 0.0023  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0059  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:21:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1750/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:10  time: 1.3900  data_time: 0.0244  memory: 4504  loss: 0.1869  sup_loss_rpn_cls: 0.0068  sup_loss_rpn_bbox: 0.0071  sup_loss_cls: 0.0825  sup_acc: 97.8516  sup_loss_bbox: 0.0780  unsup_loss_rpn_cls: 0.0027  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0097  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:22:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1800/180000]  lr: 1.0000e-02  eta: 2 days, 20:12:57  time: 1.3890  data_time: 0.0265  memory: 4504  loss: 0.1764  sup_loss_rpn_cls: 0.0059  sup_loss_rpn_bbox: 0.0058  sup_loss_cls: 0.0760  sup_acc: 98.0469  sup_loss_bbox: 0.0761  unsup_loss_rpn_cls: 0.0033  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0093  unsup_acc: 99.8535  unsup_loss_bbox: 0.0000\n",
            "06/21 06:24:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1850/180000]  lr: 1.0000e-02  eta: 2 days, 20:12:47  time: 1.3902  data_time: 0.0244  memory: 4504  loss: 0.1648  sup_loss_rpn_cls: 0.0059  sup_loss_rpn_bbox: 0.0070  sup_loss_cls: 0.0706  sup_acc: 97.8516  sup_loss_bbox: 0.0727  unsup_loss_rpn_cls: 0.0025  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0061  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:25:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1900/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:47  time: 1.4061  data_time: 0.0273  memory: 4504  loss: 0.1711  sup_loss_rpn_cls: 0.0075  sup_loss_rpn_bbox: 0.0058  sup_loss_cls: 0.0758  sup_acc: 97.6562  sup_loss_bbox: 0.0733  unsup_loss_rpn_cls: 0.0028  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0059  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:26:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  1950/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:05  time: 1.3849  data_time: 0.0258  memory: 4505  loss: 0.1635  sup_loss_rpn_cls: 0.0077  sup_loss_rpn_bbox: 0.0070  sup_loss_cls: 0.0658  sup_acc: 97.2656  sup_loss_bbox: 0.0759  unsup_loss_rpn_cls: 0.0019  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0052  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:27:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco_20230621_054100\n",
            "06/21 06:27:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2000/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:07  time: 1.3952  data_time: 0.0252  memory: 4505  loss: 0.1668  sup_loss_rpn_cls: 0.0044  sup_loss_rpn_bbox: 0.0059  sup_loss_cls: 0.0730  sup_acc: 97.0703  sup_loss_bbox: 0.0752  unsup_loss_rpn_cls: 0.0025  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0058  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:28:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2050/180000]  lr: 1.0000e-02  eta: 2 days, 20:12:29  time: 1.3868  data_time: 0.0257  memory: 4504  loss: 0.1706  sup_loss_rpn_cls: 0.0053  sup_loss_rpn_bbox: 0.0059  sup_loss_cls: 0.0695  sup_acc: 97.0703  sup_loss_bbox: 0.0835  unsup_loss_rpn_cls: 0.0016  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0047  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:29:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2100/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:25  time: 1.4094  data_time: 0.0261  memory: 4504  loss: 0.1604  sup_loss_rpn_cls: 0.0057  sup_loss_rpn_bbox: 0.0064  sup_loss_cls: 0.0627  sup_acc: 98.4375  sup_loss_bbox: 0.0764  unsup_loss_rpn_cls: 0.0026  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0065  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:31:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2150/180000]  lr: 1.0000e-02  eta: 2 days, 20:12:24  time: 1.3825  data_time: 0.0240  memory: 4504  loss: 0.1798  sup_loss_rpn_cls: 0.0052  sup_loss_rpn_bbox: 0.0073  sup_loss_cls: 0.0672  sup_acc: 97.2656  sup_loss_bbox: 0.0901  unsup_loss_rpn_cls: 0.0018  unsup_loss_rpn_bbox: 0.0001  unsup_loss_cls: 0.0080  unsup_acc: 99.5117  unsup_loss_bbox: 0.0000\n",
            "06/21 06:32:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2200/180000]  lr: 1.0000e-02  eta: 2 days, 20:11:45  time: 1.3883  data_time: 0.0251  memory: 4504  loss: 0.1545  sup_loss_rpn_cls: 0.0050  sup_loss_rpn_bbox: 0.0051  sup_loss_cls: 0.0617  sup_acc: 97.2656  sup_loss_bbox: 0.0754  unsup_loss_rpn_cls: 0.0023  unsup_loss_rpn_bbox: 0.0001  unsup_loss_cls: 0.0049  unsup_acc: 99.9512  unsup_loss_bbox: 0.0000\n",
            "06/21 06:33:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2250/180000]  lr: 1.0000e-02  eta: 2 days, 20:11:18  time: 1.3914  data_time: 0.0257  memory: 4504  loss: 0.1532  sup_loss_rpn_cls: 0.0055  sup_loss_rpn_bbox: 0.0070  sup_loss_cls: 0.0614  sup_acc: 98.2422  sup_loss_bbox: 0.0717  unsup_loss_rpn_cls: 0.0024  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0052  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000\n",
            "06/21 06:34:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2300/180000]  lr: 1.0000e-02  eta: 2 days, 20:10:31  time: 1.3865  data_time: 0.0266  memory: 4504  loss: 0.1251  sup_loss_rpn_cls: 0.0040  sup_loss_rpn_bbox: 0.0057  sup_loss_cls: 0.0431  sup_acc: 98.4375  sup_loss_bbox: 0.0607  unsup_loss_rpn_cls: 0.0019  unsup_loss_rpn_bbox: 0.0003  unsup_loss_cls: 0.0082  unsup_acc: 100.0000  unsup_loss_bbox: 0.0012\n",
            "06/21 06:35:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2350/180000]  lr: 1.0000e-02  eta: 2 days, 20:09:29  time: 1.3830  data_time: 0.0248  memory: 4504  loss: 0.1467  sup_loss_rpn_cls: 0.0054  sup_loss_rpn_bbox: 0.0061  sup_loss_cls: 0.0552  sup_acc: 98.6328  sup_loss_bbox: 0.0605  unsup_loss_rpn_cls: 0.0045  unsup_loss_rpn_bbox: 0.0003  unsup_loss_cls: 0.0134  unsup_acc: 100.0000  unsup_loss_bbox: 0.0013\n",
            "06/21 06:36:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2400/180000]  lr: 1.0000e-02  eta: 2 days, 20:08:43  time: 1.3875  data_time: 0.0254  memory: 4504  loss: 0.1482  sup_loss_rpn_cls: 0.0038  sup_loss_rpn_bbox: 0.0065  sup_loss_cls: 0.0575  sup_acc: 98.8281  sup_loss_bbox: 0.0642  unsup_loss_rpn_cls: 0.0028  unsup_loss_rpn_bbox: 0.0010  unsup_loss_cls: 0.0118  unsup_acc: 100.0000  unsup_loss_bbox: 0.0007\n",
            "06/21 06:38:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2450/180000]  lr: 1.0000e-02  eta: 2 days, 20:09:41  time: 1.4166  data_time: 0.0251  memory: 4504  loss: 0.1461  sup_loss_rpn_cls: 0.0045  sup_loss_rpn_bbox: 0.0055  sup_loss_cls: 0.0548  sup_acc: 99.6094  sup_loss_bbox: 0.0657  unsup_loss_rpn_cls: 0.0033  unsup_loss_rpn_bbox: 0.0001  unsup_loss_cls: 0.0105  unsup_acc: 100.0000  unsup_loss_bbox: 0.0016\n",
            "06/21 06:39:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2500/180000]  lr: 1.0000e-02  eta: 2 days, 20:10:06  time: 1.4084  data_time: 0.0260  memory: 4504  loss: 0.1732  sup_loss_rpn_cls: 0.0060  sup_loss_rpn_bbox: 0.0063  sup_loss_cls: 0.0646  sup_acc: 96.6797  sup_loss_bbox: 0.0712  unsup_loss_rpn_cls: 0.0062  unsup_loss_rpn_bbox: 0.0006  unsup_loss_cls: 0.0174  unsup_acc: 99.0234  unsup_loss_bbox: 0.0008\n",
            "06/21 06:40:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2550/180000]  lr: 1.0000e-02  eta: 2 days, 20:11:17  time: 1.4228  data_time: 0.0248  memory: 4504  loss: 0.1434  sup_loss_rpn_cls: 0.0047  sup_loss_rpn_bbox: 0.0053  sup_loss_cls: 0.0554  sup_acc: 99.6094  sup_loss_bbox: 0.0643  unsup_loss_rpn_cls: 0.0019  unsup_loss_rpn_bbox: 0.0001  unsup_loss_cls: 0.0084  unsup_acc: 100.0000  unsup_loss_bbox: 0.0032\n",
            "06/21 06:41:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2600/180000]  lr: 1.0000e-02  eta: 2 days, 20:10:48  time: 1.3953  data_time: 0.0245  memory: 4504  loss: 0.1736  sup_loss_rpn_cls: 0.0064  sup_loss_rpn_bbox: 0.0061  sup_loss_cls: 0.0607  sup_acc: 98.2422  sup_loss_bbox: 0.0742  unsup_loss_rpn_cls: 0.0059  unsup_loss_rpn_bbox: 0.0002  unsup_loss_cls: 0.0190  unsup_acc: 100.0000  unsup_loss_bbox: 0.0010\n",
            "06/21 06:42:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2650/180000]  lr: 1.0000e-02  eta: 2 days, 20:10:26  time: 1.3975  data_time: 0.0253  memory: 4504  loss: 0.1549  sup_loss_rpn_cls: 0.0063  sup_loss_rpn_bbox: 0.0051  sup_loss_cls: 0.0583  sup_acc: 96.4844  sup_loss_bbox: 0.0709  unsup_loss_rpn_cls: 0.0024  unsup_loss_rpn_bbox: 0.0005  unsup_loss_cls: 0.0092  unsup_acc: 100.0000  unsup_loss_bbox: 0.0022\n",
            "06/21 06:43:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2700/180000]  lr: 1.0000e-02  eta: 2 days, 20:09:56  time: 1.3959  data_time: 0.0242  memory: 4504  loss: 0.1582  sup_loss_rpn_cls: 0.0039  sup_loss_rpn_bbox: 0.0066  sup_loss_cls: 0.0589  sup_acc: 98.6328  sup_loss_bbox: 0.0657  unsup_loss_rpn_cls: 0.0047  unsup_loss_rpn_bbox: 0.0003  unsup_loss_cls: 0.0163  unsup_acc: 99.7559  unsup_loss_bbox: 0.0018\n",
            "06/21 06:45:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2750/180000]  lr: 1.0000e-02  eta: 2 days, 20:08:23  time: 1.3768  data_time: 0.0239  memory: 4504  loss: 0.1800  sup_loss_rpn_cls: 0.0077  sup_loss_rpn_bbox: 0.0054  sup_loss_cls: 0.0698  sup_acc: 98.2422  sup_loss_bbox: 0.0787  unsup_loss_rpn_cls: 0.0036  unsup_loss_rpn_bbox: 0.0003  unsup_loss_cls: 0.0115  unsup_acc: 99.4629  unsup_loss_bbox: 0.0029\n",
            "06/21 06:46:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2800/180000]  lr: 1.0000e-02  eta: 2 days, 20:07:05  time: 1.3812  data_time: 0.0238  memory: 4504  loss: 0.1448  sup_loss_rpn_cls: 0.0039  sup_loss_rpn_bbox: 0.0055  sup_loss_cls: 0.0561  sup_acc: 98.8281  sup_loss_bbox: 0.0694  unsup_loss_rpn_cls: 0.0024  unsup_loss_rpn_bbox: 0.0001  unsup_loss_cls: 0.0069  unsup_acc: 100.0000  unsup_loss_bbox: 0.0005\n",
            "06/21 06:47:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2850/180000]  lr: 1.0000e-02  eta: 2 days, 20:06:33  time: 1.3958  data_time: 0.0256  memory: 4504  loss: 0.1474  sup_loss_rpn_cls: 0.0025  sup_loss_rpn_bbox: 0.0057  sup_loss_cls: 0.0505  sup_acc: 97.2656  sup_loss_bbox: 0.0682  unsup_loss_rpn_cls: 0.0034  unsup_loss_rpn_bbox: 0.0007  unsup_loss_cls: 0.0137  unsup_acc: 100.0000  unsup_loss_bbox: 0.0026\n",
            "06/21 06:48:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2900/180000]  lr: 1.0000e-02  eta: 2 days, 20:06:34  time: 1.4070  data_time: 0.0252  memory: 4504  loss: 0.1460  sup_loss_rpn_cls: 0.0047  sup_loss_rpn_bbox: 0.0060  sup_loss_cls: 0.0505  sup_acc: 98.0469  sup_loss_bbox: 0.0736  unsup_loss_rpn_cls: 0.0019  unsup_loss_rpn_bbox: 0.0001  unsup_loss_cls: 0.0068  unsup_acc: 100.0000  unsup_loss_bbox: 0.0023\n",
            "06/21 06:49:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  2950/180000]  lr: 1.0000e-02  eta: 2 days, 20:06:12  time: 1.4004  data_time: 0.0250  memory: 4505  loss: 0.1867  sup_loss_rpn_cls: 0.0044  sup_loss_rpn_bbox: 0.0061  sup_loss_cls: 0.0618  sup_acc: 99.4141  sup_loss_bbox: 0.0757  unsup_loss_rpn_cls: 0.0106  unsup_loss_rpn_bbox: 0.0014  unsup_loss_cls: 0.0241  unsup_acc: 100.0000  unsup_loss_bbox: 0.0025\n",
            "06/21 06:50:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco_20230621_054100\n",
            "06/21 06:50:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  3000/180000]  lr: 1.0000e-02  eta: 2 days, 20:05:55  time: 1.4024  data_time: 0.0268  memory: 4504  loss: 0.1432  sup_loss_rpn_cls: 0.0030  sup_loss_rpn_bbox: 0.0057  sup_loss_cls: 0.0522  sup_acc: 98.6328  sup_loss_bbox: 0.0694  unsup_loss_rpn_cls: 0.0023  unsup_loss_rpn_bbox: 0.0002  unsup_loss_cls: 0.0085  unsup_acc: 100.0000  unsup_loss_bbox: 0.0019\n",
            "06/21 06:52:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  3050/180000]  lr: 1.0000e-02  eta: 2 days, 20:05:32  time: 1.4008  data_time: 0.0247  memory: 4504  loss: 0.1395  sup_loss_rpn_cls: 0.0030  sup_loss_rpn_bbox: 0.0052  sup_loss_cls: 0.0455  sup_acc: 98.6328  sup_loss_bbox: 0.0608  unsup_loss_rpn_cls: 0.0023  unsup_loss_rpn_bbox: 0.0005  unsup_loss_cls: 0.0148  unsup_acc: 100.0000  unsup_loss_bbox: 0.0073\n",
            "06/21 06:53:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  3100/180000]  lr: 1.0000e-02  eta: 2 days, 20:05:25  time: 1.4072  data_time: 0.0253  memory: 4504  loss: 0.1429  sup_loss_rpn_cls: 0.0031  sup_loss_rpn_bbox: 0.0050  sup_loss_cls: 0.0370  sup_acc: 99.2188  sup_loss_bbox: 0.0669  unsup_loss_rpn_cls: 0.0061  unsup_loss_rpn_bbox: 0.0013  unsup_loss_cls: 0.0104  unsup_acc: 100.0000  unsup_loss_bbox: 0.0132\n",
            "06/21 06:54:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  3150/180000]  lr: 1.0000e-02  eta: 2 days, 20:04:20  time: 1.3875  data_time: 0.0250  memory: 4504  loss: 0.1283  sup_loss_rpn_cls: 0.0028  sup_loss_rpn_bbox: 0.0066  sup_loss_cls: 0.0459  sup_acc: 98.4375  sup_loss_bbox: 0.0662  unsup_loss_rpn_cls: 0.0008  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0049  unsup_acc: 99.9512  unsup_loss_bbox: 0.0011\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/mmdetection/tools/train.py\", line 133, in <module>\n",
            "    main()\n",
            "  File \"/content/mmdetection/tools/train.py\", line 129, in main\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1721, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 278, in run\n",
            "    self.run_iter(data_batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 301, in run_iter\n",
            "    outputs = self.runner.model.train_step(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\", line 114, in train_step\n",
            "    losses = self._run_forward(data, mode='loss')  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\", line 340, in _run_forward\n",
            "    results = self(**data, mode=mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/mmdetection/mmdet/models/detectors/base.py\", line 92, in forward\n",
            "    return self.loss(inputs, data_samples)\n",
            "  File \"/content/mmdetection/mmdet/models/detectors/semi_base.py\", line 80, in loss\n",
            "    origin_pseudo_data_samples, batch_info = self.get_pseudo_instances(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/mmdetection/mmdet/models/detectors/soft_teacher.py\", line 103, in get_pseudo_instances\n",
            "    results_list = self.teacher.roi_head.predict(\n",
            "  File \"/content/mmdetection/mmdet/models/roi_heads/base_roi_head.py\", line 118, in predict\n",
            "    results_list = self.predict_bbox(\n",
            "  File \"/content/mmdetection/mmdet/models/roi_heads/standard_roi_head.py\", line 335, in predict_bbox\n",
            "    bbox_results = self._bbox_forward(x, rois)\n",
            "  File \"/content/mmdetection/mmdet/models/roi_heads/standard_roi_head.py\", line 163, in _bbox_forward\n",
            "    bbox_feats = self.bbox_roi_extractor(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/mmdetection/mmdet/models/roi_heads/roi_extractors/single_level_roi_extractor.py\", line 104, in forward\n",
            "    inds = mask.nonzero(as_tuple=False).squeeze(1)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the checkpoints can be saved in the given path in train.py file OR found in content/mmdetection/work_dirs/softteacher...../checkpoints.pth"
      ],
      "metadata": {
        "id": "3gq9G28Yx21_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}