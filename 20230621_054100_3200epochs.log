2023/06/21 05:41:01 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0]
    CUDA available: True
    numpy_random_seed: 1264885612
    GPU 0: Tesla T4
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.8, V11.8.89
    GCC: x86_64-linux-gnu-gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
    PyTorch: 2.0.1+cu118
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.15.2+cu118
    OpenCV: 4.7.0
    MMEngine: 0.7.4

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1264885612
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2023/06/21 05:41:08 - mmengine - INFO - Config:
model = dict(
    type='SoftTeacher',
    detector=dict(
        type='FasterRCNN',
        data_preprocessor=dict(
            type='DetDataPreprocessor',
            mean=[103.53, 116.28, 123.675],
            std=[1.0, 1.0, 1.0],
            bgr_to_rgb=False,
            pad_size_divisor=32),
        backbone=dict(
            type='ResNet',
            depth=50,
            num_stages=4,
            out_indices=(0, 1, 2, 3),
            frozen_stages=1,
            norm_cfg=dict(type='BN', requires_grad=False),
            norm_eval=True,
            style='caffe',
            init_cfg=dict(
                type='Pretrained',
                checkpoint='open-mmlab://detectron2/resnet50_caffe')),
        neck=dict(
            type='FPN',
            in_channels=[256, 512, 1024, 2048],
            out_channels=256,
            num_outs=5),
        rpn_head=dict(
            type='RPNHead',
            in_channels=256,
            feat_channels=256,
            anchor_generator=dict(
                type='AnchorGenerator',
                scales=[8],
                ratios=[0.5, 1.0, 2.0],
                strides=[4, 8, 16, 32, 64]),
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[1.0, 1.0, 1.0, 1.0]),
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
        roi_head=dict(
            type='StandardRoIHead',
            bbox_roi_extractor=dict(
                type='SingleRoIExtractor',
                roi_layer=dict(
                    type='RoIAlign', output_size=7, sampling_ratio=0),
                out_channels=256,
                featmap_strides=[4, 8, 16, 32]),
            bbox_head=dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=80,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=False,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='L1Loss', loss_weight=1.0))),
        train_cfg=dict(
            rpn=dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.3,
                    min_pos_iou=0.3,
                    match_low_quality=True,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=256,
                    pos_fraction=0.5,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=False),
                allowed_border=-1,
                pos_weight=-1,
                debug=False),
            rpn_proposal=dict(
                nms_pre=2000,
                max_per_img=1000,
                nms=dict(type='nms', iou_threshold=0.7),
                min_bbox_size=0),
            rcnn=dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False)),
        test_cfg=dict(
            rpn=dict(
                nms_pre=1000,
                max_per_img=1000,
                nms=dict(type='nms', iou_threshold=0.7),
                min_bbox_size=0),
            rcnn=dict(
                score_thr=0.05,
                nms=dict(type='nms', iou_threshold=0.5),
                max_per_img=100))),
    data_preprocessor=dict(
        type='MultiBranchDataPreprocessor',
        data_preprocessor=dict(
            type='DetDataPreprocessor',
            mean=[103.53, 116.28, 123.675],
            std=[1.0, 1.0, 1.0],
            bgr_to_rgb=False,
            pad_size_divisor=32)),
    semi_train_cfg=dict(
        freeze_teacher=True,
        sup_weight=1.0,
        unsup_weight=4.0,
        pseudo_label_initial_score_thr=0.5,
        rpn_pseudo_thr=0.9,
        cls_pseudo_thr=0.9,
        reg_pseudo_thr=0.02,
        jitter_times=10,
        jitter_scale=0.06,
        min_pseudo_bbox_wh=(0.01, 0.01)),
    semi_test_cfg=dict(predict_on='teacher'))
default_scope = 'mmdet'
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=50),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(
        type='CheckpointHook',
        interval=10000,
        by_epoch=False,
        max_keep_ckpts=2),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(type='DetVisualizationHook'))
env_cfg = dict(
    cudnn_benchmark=False,
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='nccl'))
vis_backends = [dict(type='LocalVisBackend')]
visualizer = dict(
    type='DetLocalVisualizer',
    vis_backends=[dict(type='LocalVisBackend')],
    name='visualizer')
log_processor = dict(type='LogProcessor', window_size=50, by_epoch=False)
log_level = 'INFO'
load_from = None
resume = True
dataset_type = 'CocoDataset'
data_root = 'data/coco/'
backend_args = None
color_space = [[{
    'type': 'ColorTransform'
}], [{
    'type': 'AutoContrast'
}], [{
    'type': 'Equalize'
}], [{
    'type': 'Sharpness'
}], [{
    'type': 'Posterize'
}], [{
    'type': 'Solarize'
}], [{
    'type': 'Color'
}], [{
    'type': 'Contrast'
}], [{
    'type': 'Brightness'
}]]
geometric = [[{
    'type': 'Rotate'
}], [{
    'type': 'ShearX'
}], [{
    'type': 'ShearY'
}], [{
    'type': 'TranslateX'
}], [{
    'type': 'TranslateY'
}]]
scale = [(1333, 400), (1333, 1200)]
branch_field = ['sup', 'unsup_teacher', 'unsup_student']
sup_pipeline = [
    dict(type='LoadImageFromFile', backend_args=None),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='RandomResize',
        scale=[(1333, 400), (1333, 1200)],
        keep_ratio=True),
    dict(type='RandomFlip', prob=0.5),
    dict(
        type='RandAugment',
        aug_space=[[{
            'type': 'ColorTransform'
        }], [{
            'type': 'AutoContrast'
        }], [{
            'type': 'Equalize'
        }], [{
            'type': 'Sharpness'
        }], [{
            'type': 'Posterize'
        }], [{
            'type': 'Solarize'
        }], [{
            'type': 'Color'
        }], [{
            'type': 'Contrast'
        }], [{
            'type': 'Brightness'
        }]],
        aug_num=1),
    dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),
    dict(
        type='MultiBranch',
        branch_field=['sup', 'unsup_teacher', 'unsup_student'],
        sup=dict(type='PackDetInputs'))
]
weak_pipeline = [
    dict(
        type='RandomResize',
        scale=[(1333, 400), (1333, 1200)],
        keep_ratio=True),
    dict(type='RandomFlip', prob=0.5),
    dict(
        type='PackDetInputs',
        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                   'scale_factor', 'flip', 'flip_direction',
                   'homography_matrix'))
]
strong_pipeline = [
    dict(
        type='RandomResize',
        scale=[(1333, 400), (1333, 1200)],
        keep_ratio=True),
    dict(type='RandomFlip', prob=0.5),
    dict(
        type='RandomOrder',
        transforms=[
            dict(
                type='RandAugment',
                aug_space=[[{
                    'type': 'ColorTransform'
                }], [{
                    'type': 'AutoContrast'
                }], [{
                    'type': 'Equalize'
                }], [{
                    'type': 'Sharpness'
                }], [{
                    'type': 'Posterize'
                }], [{
                    'type': 'Solarize'
                }], [{
                    'type': 'Color'
                }], [{
                    'type': 'Contrast'
                }], [{
                    'type': 'Brightness'
                }]],
                aug_num=1),
            dict(
                type='RandAugment',
                aug_space=[[{
                    'type': 'Rotate'
                }], [{
                    'type': 'ShearX'
                }], [{
                    'type': 'ShearY'
                }], [{
                    'type': 'TranslateX'
                }], [{
                    'type': 'TranslateY'
                }]],
                aug_num=1)
        ]),
    dict(type='RandomErasing', n_patches=(1, 5), ratio=(0, 0.2)),
    dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),
    dict(
        type='PackDetInputs',
        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                   'scale_factor', 'flip', 'flip_direction',
                   'homography_matrix'))
]
unsup_pipeline = [
    dict(type='LoadImageFromFile', backend_args=None),
    dict(type='LoadEmptyAnnotations'),
    dict(
        type='MultiBranch',
        branch_field=['sup', 'unsup_teacher', 'unsup_student'],
        unsup_teacher=[
            dict(
                type='RandomResize',
                scale=[(1333, 400), (1333, 1200)],
                keep_ratio=True),
            dict(type='RandomFlip', prob=0.5),
            dict(
                type='PackDetInputs',
                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                           'scale_factor', 'flip', 'flip_direction',
                           'homography_matrix'))
        ],
        unsup_student=[
            dict(
                type='RandomResize',
                scale=[(1333, 400), (1333, 1200)],
                keep_ratio=True),
            dict(type='RandomFlip', prob=0.5),
            dict(
                type='RandomOrder',
                transforms=[
                    dict(
                        type='RandAugment',
                        aug_space=[[{
                            'type': 'ColorTransform'
                        }], [{
                            'type': 'AutoContrast'
                        }], [{
                            'type': 'Equalize'
                        }], [{
                            'type': 'Sharpness'
                        }], [{
                            'type': 'Posterize'
                        }], [{
                            'type': 'Solarize'
                        }], [{
                            'type': 'Color'
                        }], [{
                            'type': 'Contrast'
                        }], [{
                            'type': 'Brightness'
                        }]],
                        aug_num=1),
                    dict(
                        type='RandAugment',
                        aug_space=[[{
                            'type': 'Rotate'
                        }], [{
                            'type': 'ShearX'
                        }], [{
                            'type': 'ShearY'
                        }], [{
                            'type': 'TranslateX'
                        }], [{
                            'type': 'TranslateY'
                        }]],
                        aug_num=1)
                ]),
            dict(type='RandomErasing', n_patches=(1, 5), ratio=(0, 0.2)),
            dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),
            dict(
                type='PackDetInputs',
                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                           'scale_factor', 'flip', 'flip_direction',
                           'homography_matrix'))
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile', backend_args=None),
    dict(type='Resize', scale=(1333, 800), keep_ratio=True),
    dict(
        type='PackDetInputs',
        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                   'scale_factor'))
]
batch_size = 5
num_workers = 5
labeled_dataset = dict(
    type='CocoDataset',
    data_root='data/coco/',
    ann_file='annotations/coco_annotations.json',
    data_prefix=dict(img='train/'),
    filter_cfg=dict(filter_empty_gt=True, min_size=32),
    pipeline=[
        dict(type='LoadImageFromFile', backend_args=None),
        dict(type='LoadAnnotations', with_bbox=True),
        dict(
            type='RandomResize',
            scale=[(1333, 400), (1333, 1200)],
            keep_ratio=True),
        dict(type='RandomFlip', prob=0.5),
        dict(
            type='RandAugment',
            aug_space=[[{
                'type': 'ColorTransform'
            }], [{
                'type': 'AutoContrast'
            }], [{
                'type': 'Equalize'
            }], [{
                'type': 'Sharpness'
            }], [{
                'type': 'Posterize'
            }], [{
                'type': 'Solarize'
            }], [{
                'type': 'Color'
            }], [{
                'type': 'Contrast'
            }], [{
                'type': 'Brightness'
            }]],
            aug_num=1),
        dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),
        dict(
            type='MultiBranch',
            branch_field=['sup', 'unsup_teacher', 'unsup_student'],
            sup=dict(type='PackDetInputs'))
    ],
    backend_args=None)
unlabeled_dataset = dict(
    type='CocoDataset',
    data_root='data/coco/',
    ann_file='annotations/val_coco_annotations.json',
    data_prefix=dict(img='val/'),
    filter_cfg=dict(filter_empty_gt=False),
    pipeline=[
        dict(type='LoadImageFromFile', backend_args=None),
        dict(type='LoadEmptyAnnotations'),
        dict(
            type='MultiBranch',
            branch_field=['sup', 'unsup_teacher', 'unsup_student'],
            unsup_teacher=[
                dict(
                    type='RandomResize',
                    scale=[(1333, 400), (1333, 1200)],
                    keep_ratio=True),
                dict(type='RandomFlip', prob=0.5),
                dict(
                    type='PackDetInputs',
                    meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                               'scale_factor', 'flip', 'flip_direction',
                               'homography_matrix'))
            ],
            unsup_student=[
                dict(
                    type='RandomResize',
                    scale=[(1333, 400), (1333, 1200)],
                    keep_ratio=True),
                dict(type='RandomFlip', prob=0.5),
                dict(
                    type='RandomOrder',
                    transforms=[
                        dict(
                            type='RandAugment',
                            aug_space=[[{
                                'type': 'ColorTransform'
                            }], [{
                                'type': 'AutoContrast'
                            }], [{
                                'type': 'Equalize'
                            }], [{
                                'type': 'Sharpness'
                            }], [{
                                'type': 'Posterize'
                            }], [{
                                'type': 'Solarize'
                            }], [{
                                'type': 'Color'
                            }], [{
                                'type': 'Contrast'
                            }], [{
                                'type': 'Brightness'
                            }]],
                            aug_num=1),
                        dict(
                            type='RandAugment',
                            aug_space=[[{
                                'type': 'Rotate'
                            }], [{
                                'type': 'ShearX'
                            }], [{
                                'type': 'ShearY'
                            }], [{
                                'type': 'TranslateX'
                            }], [{
                                'type': 'TranslateY'
                            }]],
                            aug_num=1)
                    ]),
                dict(type='RandomErasing', n_patches=(1, 5), ratio=(0, 0.2)),
                dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),
                dict(
                    type='PackDetInputs',
                    meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                               'scale_factor', 'flip', 'flip_direction',
                               'homography_matrix'))
            ])
    ],
    backend_args=None)
train_dataloader = dict(
    batch_size=5,
    num_workers=5,
    persistent_workers=True,
    sampler=dict(
        type='GroupMultiSourceSampler', batch_size=5, source_ratio=[1, 4]),
    dataset=dict(
        type='ConcatDataset',
        datasets=[
            dict(
                type='CocoDataset',
                data_root='data/coco/',
                ann_file='annotations/coco_annotations.json',
                data_prefix=dict(img='train/'),
                filter_cfg=dict(filter_empty_gt=True, min_size=32),
                pipeline=[
                    dict(type='LoadImageFromFile', backend_args=None),
                    dict(type='LoadAnnotations', with_bbox=True),
                    dict(
                        type='RandomResize',
                        scale=[(1333, 400), (1333, 1200)],
                        keep_ratio=True),
                    dict(type='RandomFlip', prob=0.5),
                    dict(
                        type='RandAugment',
                        aug_space=[[{
                            'type': 'ColorTransform'
                        }], [{
                            'type': 'AutoContrast'
                        }], [{
                            'type': 'Equalize'
                        }], [{
                            'type': 'Sharpness'
                        }], [{
                            'type': 'Posterize'
                        }], [{
                            'type': 'Solarize'
                        }], [{
                            'type': 'Color'
                        }], [{
                            'type': 'Contrast'
                        }], [{
                            'type': 'Brightness'
                        }]],
                        aug_num=1),
                    dict(
                        type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),
                    dict(
                        type='MultiBranch',
                        branch_field=['sup', 'unsup_teacher', 'unsup_student'],
                        sup=dict(type='PackDetInputs'))
                ],
                backend_args=None),
            dict(
                type='CocoDataset',
                data_root='data/coco/',
                ann_file='annotations/val_coco_annotations.json',
                data_prefix=dict(img='val/'),
                filter_cfg=dict(filter_empty_gt=False),
                pipeline=[
                    dict(type='LoadImageFromFile', backend_args=None),
                    dict(type='LoadEmptyAnnotations'),
                    dict(
                        type='MultiBranch',
                        branch_field=['sup', 'unsup_teacher', 'unsup_student'],
                        unsup_teacher=[
                            dict(
                                type='RandomResize',
                                scale=[(1333, 400), (1333, 1200)],
                                keep_ratio=True),
                            dict(type='RandomFlip', prob=0.5),
                            dict(
                                type='PackDetInputs',
                                meta_keys=('img_id', 'img_path', 'ori_shape',
                                           'img_shape', 'scale_factor', 'flip',
                                           'flip_direction',
                                           'homography_matrix'))
                        ],
                        unsup_student=[
                            dict(
                                type='RandomResize',
                                scale=[(1333, 400), (1333, 1200)],
                                keep_ratio=True),
                            dict(type='RandomFlip', prob=0.5),
                            dict(
                                type='RandomOrder',
                                transforms=[
                                    dict(
                                        type='RandAugment',
                                        aug_space=[[{
                                            'type': 'ColorTransform'
                                        }], [{
                                            'type': 'AutoContrast'
                                        }], [{
                                            'type': 'Equalize'
                                        }], [{
                                            'type': 'Sharpness'
                                        }], [{
                                            'type': 'Posterize'
                                        }], [{
                                            'type': 'Solarize'
                                        }], [{
                                            'type': 'Color'
                                        }], [{
                                            'type': 'Contrast'
                                        }], [{
                                            'type': 'Brightness'
                                        }]],
                                        aug_num=1),
                                    dict(
                                        type='RandAugment',
                                        aug_space=[[{
                                            'type': 'Rotate'
                                        }], [{
                                            'type': 'ShearX'
                                        }], [{
                                            'type': 'ShearY'
                                        }], [{
                                            'type': 'TranslateX'
                                        }], [{
                                            'type': 'TranslateY'
                                        }]],
                                        aug_num=1)
                                ]),
                            dict(
                                type='RandomErasing',
                                n_patches=(1, 5),
                                ratio=(0, 0.2)),
                            dict(
                                type='FilterAnnotations',
                                min_gt_bbox_wh=(0.01, 0.01)),
                            dict(
                                type='PackDetInputs',
                                meta_keys=('img_id', 'img_path', 'ori_shape',
                                           'img_shape', 'scale_factor', 'flip',
                                           'flip_direction',
                                           'homography_matrix'))
                        ])
                ],
                backend_args=None)
        ]))
val_dataloader = dict(
    batch_size=1,
    num_workers=2,
    persistent_workers=True,
    drop_last=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='CocoDataset',
        data_root='data/coco/',
        ann_file='annotations/val_coco_annotations.json',
        data_prefix=dict(img='val2017/'),
        test_mode=True,
        pipeline=[
            dict(type='LoadImageFromFile', backend_args=None),
            dict(type='Resize', scale=(1333, 800), keep_ratio=True),
            dict(
                type='PackDetInputs',
                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                           'scale_factor'))
        ],
        backend_args=None))
test_dataloader = dict(
    batch_size=1,
    num_workers=2,
    persistent_workers=True,
    drop_last=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='CocoDataset',
        data_root='data/coco/',
        ann_file='annotations/val_coco_annotations.json',
        data_prefix=dict(img='val2017/'),
        test_mode=True,
        pipeline=[
            dict(type='LoadImageFromFile', backend_args=None),
            dict(type='Resize', scale=(1333, 800), keep_ratio=True),
            dict(
                type='PackDetInputs',
                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                           'scale_factor'))
        ],
        backend_args=None))
val_evaluator = dict(
    type='CocoMetric',
    ann_file='data/coco/annotations/val_coco_annotations.json',
    metric='bbox',
    format_only=False,
    backend_args=None)
test_evaluator = dict(
    type='CocoMetric',
    ann_file='data/coco/annotations/val_coco_annotations.json',
    metric='bbox',
    format_only=False,
    backend_args=None)
detector = dict(
    type='FasterRCNN',
    data_preprocessor=dict(
        type='DetDataPreprocessor',
        mean=[103.53, 116.28, 123.675],
        std=[1.0, 1.0, 1.0],
        bgr_to_rgb=False,
        pad_size_divisor=32),
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=False),
        norm_eval=True,
        style='caffe',
        init_cfg=dict(
            type='Pretrained',
            checkpoint='open-mmlab://detectron2/resnet50_caffe')),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    roi_head=dict(
        type='StandardRoIHead',
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=dict(
            type='Shared2FCBBoxHead',
            in_channels=256,
            fc_out_channels=1024,
            roi_feat_size=7,
            num_classes=80,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            reg_class_agnostic=False,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=-1,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.5,
                neg_iou_thr=0.5,
                min_pos_iou=0.5,
                match_low_quality=False,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=512,
                pos_fraction=0.25,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            pos_weight=-1,
            debug=False)),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100)))
train_cfg = dict(
    type='IterBasedTrainLoop', max_iters=180000, val_interval=5000)
val_cfg = dict(type='TeacherStudentValLoop')
test_cfg = dict(type='TestLoop')
param_scheduler = [
    dict(
        type='LinearLR', start_factor=0.001, by_epoch=False, begin=0, end=500),
    dict(
        type='MultiStepLR',
        begin=0,
        end=180000,
        by_epoch=False,
        milestones=[120000, 160000],
        gamma=0.1)
]
optim_wrapper = dict(
    type='OptimWrapper',
    optimizer=dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001))
custom_hooks = [dict(type='MeanTeacherHook')]
launcher = 'none'
work_dir = './work_dirs/soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco'

2023/06/21 05:41:21 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2023/06/21 05:41:21 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) MeanTeacherHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) MeanTeacherHook                    
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train:
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2023/06/21 05:41:38 - mmengine - INFO - load model from: open-mmlab://detectron2/resnet50_caffe
2023/06/21 05:41:38 - mmengine - INFO - Loads checkpoint by openmmlab backend from path: open-mmlab://detectron2/resnet50_caffe
2023/06/21 05:41:38 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: conv1.bias

2023/06/21 05:41:38 - mmengine - INFO - load model from: open-mmlab://detectron2/resnet50_caffe
2023/06/21 05:41:38 - mmengine - INFO - Loads checkpoint by openmmlab backend from path: open-mmlab://detectron2/resnet50_caffe
Name of parameter - Initialization information

student.backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

student.neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

student.neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

student.neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

student.neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

student.neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

student.neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

student.neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

student.neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

student.neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

student.neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

student.neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

student.neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

student.neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

student.neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

student.neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

student.neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

student.rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

student.rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

student.rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

student.rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

student.rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

student.rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

student.roi_head.bbox_head.fc_cls.weight - torch.Size([81, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

student.roi_head.bbox_head.fc_cls.bias - torch.Size([81]): 
NormalInit: mean=0, std=0.01, bias=0 

student.roi_head.bbox_head.fc_reg.weight - torch.Size([320, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

student.roi_head.bbox_head.fc_reg.bias - torch.Size([320]): 
NormalInit: mean=0, std=0.001, bias=0 

student.roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

student.roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

student.roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

student.roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://detectron2/resnet50_caffe 

teacher.neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

teacher.neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

teacher.neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

teacher.neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

teacher.neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

teacher.neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

teacher.neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

teacher.neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SoftTeacher  

teacher.rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

teacher.rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

teacher.rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

teacher.rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

teacher.rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

teacher.rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

teacher.roi_head.bbox_head.fc_cls.weight - torch.Size([81, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

teacher.roi_head.bbox_head.fc_cls.bias - torch.Size([81]): 
NormalInit: mean=0, std=0.01, bias=0 

teacher.roi_head.bbox_head.fc_reg.weight - torch.Size([320, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

teacher.roi_head.bbox_head.fc_reg.bias - torch.Size([320]): 
NormalInit: mean=0, std=0.001, bias=0 

teacher.roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 
2023/06/21 05:41:38 - mmengine - INFO - Auto resumed from the latest checkpoint None.
2023/06/21 05:41:38 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2023/06/21 05:41:38 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2023/06/21 05:41:38 - mmengine - INFO - Checkpoints will be saved to /content/mmdetection/work_dirs/soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco.
2023/06/21 05:42:43 - mmengine - INFO - Iter(train) [    50/180000]  lr: 9.9098e-04  eta: 2 days, 17:21:50  time: 1.3076  data_time: 0.0248  memory: 4504  loss: 2.6249  sup_loss_rpn_cls: 0.1815  sup_loss_rpn_bbox: 0.0116  sup_loss_cls: 0.7555  sup_acc: 96.4844  sup_loss_bbox: 0.0725  unsup_loss_rpn_cls: 0.6638  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.9400  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:43:49 - mmengine - INFO - Iter(train) [   100/180000]  lr: 1.9920e-03  eta: 2 days, 17:22:57  time: 1.3091  data_time: 0.0246  memory: 4504  loss: 0.4944  sup_loss_rpn_cls: 0.0325  sup_loss_rpn_bbox: 0.0108  sup_loss_cls: 0.3005  sup_acc: 98.2422  sup_loss_bbox: 0.1109  unsup_loss_rpn_cls: 0.0270  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0127  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:44:56 - mmengine - INFO - Iter(train) [   150/180000]  lr: 2.9930e-03  eta: 2 days, 17:56:18  time: 1.3428  data_time: 0.0245  memory: 4504  loss: 0.3445  sup_loss_rpn_cls: 0.0312  sup_loss_rpn_bbox: 0.0090  sup_loss_cls: 0.1616  sup_acc: 96.8750  sup_loss_bbox: 0.1169  unsup_loss_rpn_cls: 0.0102  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0156  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:46:05 - mmengine - INFO - Iter(train) [   200/180000]  lr: 3.9940e-03  eta: 2 days, 18:37:04  time: 1.3757  data_time: 0.0262  memory: 4504  loss: 0.3487  sup_loss_rpn_cls: 0.0257  sup_loss_rpn_bbox: 0.0088  sup_loss_cls: 0.1626  sup_acc: 96.4844  sup_loss_bbox: 0.1256  unsup_loss_rpn_cls: 0.0097  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0164  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:47:13 - mmengine - INFO - Iter(train) [   250/180000]  lr: 4.9950e-03  eta: 2 days, 18:55:26  time: 1.3664  data_time: 0.0249  memory: 4504  loss: 0.3279  sup_loss_rpn_cls: 0.0234  sup_loss_rpn_bbox: 0.0077  sup_loss_cls: 0.1533  sup_acc: 97.4609  sup_loss_bbox: 0.1170  unsup_loss_rpn_cls: 0.0084  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0180  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:48:21 - mmengine - INFO - Iter(train) [   300/180000]  lr: 5.9960e-03  eta: 2 days, 19:03:22  time: 1.3585  data_time: 0.0253  memory: 4504  loss: 0.3058  sup_loss_rpn_cls: 0.0215  sup_loss_rpn_bbox: 0.0081  sup_loss_cls: 0.1412  sup_acc: 96.2891  sup_loss_bbox: 0.1154  unsup_loss_rpn_cls: 0.0060  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0137  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:49:30 - mmengine - INFO - Iter(train) [   350/180000]  lr: 6.9970e-03  eta: 2 days, 19:15:16  time: 1.3738  data_time: 0.0255  memory: 4504  loss: 0.3066  sup_loss_rpn_cls: 0.0235  sup_loss_rpn_bbox: 0.0094  sup_loss_cls: 0.1397  sup_acc: 97.6562  sup_loss_bbox: 0.1143  unsup_loss_rpn_cls: 0.0062  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0135  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:50:38 - mmengine - INFO - Iter(train) [   400/180000]  lr: 7.9980e-03  eta: 2 days, 19:20:21  time: 1.3643  data_time: 0.0245  memory: 4504  loss: 0.2820  sup_loss_rpn_cls: 0.0202  sup_loss_rpn_bbox: 0.0079  sup_loss_cls: 0.1298  sup_acc: 96.6797  sup_loss_bbox: 0.1078  unsup_loss_rpn_cls: 0.0046  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0118  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:51:46 - mmengine - INFO - Iter(train) [   450/180000]  lr: 8.9990e-03  eta: 2 days, 19:26:21  time: 1.3712  data_time: 0.0244  memory: 4504  loss: 0.2956  sup_loss_rpn_cls: 0.0195  sup_loss_rpn_bbox: 0.0089  sup_loss_cls: 0.1404  sup_acc: 97.6562  sup_loss_bbox: 0.1040  unsup_loss_rpn_cls: 0.0087  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0140  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:52:55 - mmengine - INFO - Iter(train) [   500/180000]  lr: 1.0000e-02  eta: 2 days, 19:29:31  time: 1.3666  data_time: 0.0247  memory: 4504  loss: 0.2881  sup_loss_rpn_cls: 0.0191  sup_loss_rpn_bbox: 0.0077  sup_loss_cls: 0.1313  sup_acc: 97.4609  sup_loss_bbox: 0.1109  unsup_loss_rpn_cls: 0.0056  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0134  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:54:05 - mmengine - INFO - Iter(train) [   550/180000]  lr: 1.0000e-02  eta: 2 days, 19:39:15  time: 1.3935  data_time: 0.0263  memory: 4504  loss: 0.2926  sup_loss_rpn_cls: 0.0152  sup_loss_rpn_bbox: 0.0067  sup_loss_cls: 0.1413  sup_acc: 96.2891  sup_loss_bbox: 0.1113  unsup_loss_rpn_cls: 0.0052  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0130  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:55:14 - mmengine - INFO - Iter(train) [   600/180000]  lr: 1.0000e-02  eta: 2 days, 19:44:47  time: 1.3840  data_time: 0.0259  memory: 4504  loss: 0.2870  sup_loss_rpn_cls: 0.0177  sup_loss_rpn_bbox: 0.0075  sup_loss_cls: 0.1326  sup_acc: 97.4609  sup_loss_bbox: 0.1017  unsup_loss_rpn_cls: 0.0092  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0184  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:56:23 - mmengine - INFO - Iter(train) [   650/180000]  lr: 1.0000e-02  eta: 2 days, 19:50:37  time: 1.3897  data_time: 0.0244  memory: 4504  loss: 0.2948  sup_loss_rpn_cls: 0.0179  sup_loss_rpn_bbox: 0.0065  sup_loss_cls: 0.1359  sup_acc: 97.8516  sup_loss_bbox: 0.1100  unsup_loss_rpn_cls: 0.0072  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0173  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:57:32 - mmengine - INFO - Iter(train) [   700/180000]  lr: 1.0000e-02  eta: 2 days, 19:53:32  time: 1.3808  data_time: 0.0243  memory: 4504  loss: 0.2893  sup_loss_rpn_cls: 0.0168  sup_loss_rpn_bbox: 0.0077  sup_loss_cls: 0.1424  sup_acc: 95.8984  sup_loss_bbox: 0.0990  unsup_loss_rpn_cls: 0.0068  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0165  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:58:43 - mmengine - INFO - Iter(train) [   750/180000]  lr: 1.0000e-02  eta: 2 days, 20:01:11  time: 1.4072  data_time: 0.0270  memory: 4504  loss: 0.2643  sup_loss_rpn_cls: 0.0129  sup_loss_rpn_bbox: 0.0074  sup_loss_cls: 0.1249  sup_acc: 95.8984  sup_loss_bbox: 0.1001  unsup_loss_rpn_cls: 0.0055  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0133  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 05:59:52 - mmengine - INFO - Iter(train) [   800/180000]  lr: 1.0000e-02  eta: 2 days, 20:04:10  time: 1.3882  data_time: 0.0248  memory: 4504  loss: 0.2457  sup_loss_rpn_cls: 0.0157  sup_loss_rpn_bbox: 0.0069  sup_loss_cls: 0.1121  sup_acc: 96.8750  sup_loss_bbox: 0.0921  unsup_loss_rpn_cls: 0.0061  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0128  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:01:01 - mmengine - INFO - Iter(train) [   850/180000]  lr: 1.0000e-02  eta: 2 days, 20:06:42  time: 1.3884  data_time: 0.0249  memory: 4504  loss: 0.2742  sup_loss_rpn_cls: 0.0139  sup_loss_rpn_bbox: 0.0095  sup_loss_cls: 0.1297  sup_acc: 97.0703  sup_loss_bbox: 0.1025  unsup_loss_rpn_cls: 0.0055  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0131  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:02:11 - mmengine - INFO - Iter(train) [   900/180000]  lr: 1.0000e-02  eta: 2 days, 20:09:01  time: 1.3895  data_time: 0.0265  memory: 4504  loss: 0.2346  sup_loss_rpn_cls: 0.0111  sup_loss_rpn_bbox: 0.0068  sup_loss_cls: 0.1021  sup_acc: 97.0703  sup_loss_bbox: 0.1006  unsup_loss_rpn_cls: 0.0041  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0100  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:03:20 - mmengine - INFO - Iter(train) [   950/180000]  lr: 1.0000e-02  eta: 2 days, 20:09:14  time: 1.3786  data_time: 0.0253  memory: 4504  loss: 0.2425  sup_loss_rpn_cls: 0.0130  sup_loss_rpn_bbox: 0.0070  sup_loss_cls: 0.1107  sup_acc: 97.8516  sup_loss_bbox: 0.0979  unsup_loss_rpn_cls: 0.0046  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0092  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:04:29 - mmengine - INFO - Exp name: soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco_20230621_054100
2023/06/21 06:04:29 - mmengine - INFO - Iter(train) [  1000/180000]  lr: 1.0000e-02  eta: 2 days, 20:08:55  time: 1.3759  data_time: 0.0253  memory: 4504  loss: 0.2075  sup_loss_rpn_cls: 0.0100  sup_loss_rpn_bbox: 0.0078  sup_loss_cls: 0.0972  sup_acc: 97.2656  sup_loss_bbox: 0.0824  unsup_loss_rpn_cls: 0.0039  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0062  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:05:38 - mmengine - INFO - Iter(train) [  1050/180000]  lr: 1.0000e-02  eta: 2 days, 20:10:00  time: 1.3863  data_time: 0.0250  memory: 4504  loss: 0.2474  sup_loss_rpn_cls: 0.0103  sup_loss_rpn_bbox: 0.0071  sup_loss_cls: 0.1186  sup_acc: 97.2656  sup_loss_bbox: 0.0933  unsup_loss_rpn_cls: 0.0044  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0137  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:06:48 - mmengine - INFO - Iter(train) [  1100/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:24  time: 1.4048  data_time: 0.0274  memory: 4504  loss: 0.2374  sup_loss_rpn_cls: 0.0127  sup_loss_rpn_bbox: 0.0073  sup_loss_cls: 0.1107  sup_acc: 98.6328  sup_loss_bbox: 0.0849  unsup_loss_rpn_cls: 0.0079  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0139  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:07:58 - mmengine - INFO - Iter(train) [  1150/180000]  lr: 1.0000e-02  eta: 2 days, 20:14:23  time: 1.3893  data_time: 0.0245  memory: 4504  loss: 0.2372  sup_loss_rpn_cls: 0.0106  sup_loss_rpn_bbox: 0.0073  sup_loss_cls: 0.1104  sup_acc: 98.4375  sup_loss_bbox: 0.0887  unsup_loss_rpn_cls: 0.0056  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0147  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:09:07 - mmengine - INFO - Iter(train) [  1200/180000]  lr: 1.0000e-02  eta: 2 days, 20:15:18  time: 1.3901  data_time: 0.0264  memory: 4504  loss: 0.2217  sup_loss_rpn_cls: 0.0132  sup_loss_rpn_bbox: 0.0073  sup_loss_cls: 0.0986  sup_acc: 97.2656  sup_loss_bbox: 0.0866  unsup_loss_rpn_cls: 0.0042  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0118  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:10:16 - mmengine - INFO - Iter(train) [  1250/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:50  time: 1.3717  data_time: 0.0247  memory: 4504  loss: 0.2058  sup_loss_rpn_cls: 0.0062  sup_loss_rpn_bbox: 0.0053  sup_loss_cls: 0.0950  sup_acc: 96.2891  sup_loss_bbox: 0.0872  unsup_loss_rpn_cls: 0.0034  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0087  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:11:25 - mmengine - INFO - Iter(train) [  1300/180000]  lr: 1.0000e-02  eta: 2 days, 20:14:00  time: 1.3855  data_time: 0.0253  memory: 4504  loss: 0.2136  sup_loss_rpn_cls: 0.0102  sup_loss_rpn_bbox: 0.0065  sup_loss_cls: 0.0960  sup_acc: 98.0469  sup_loss_bbox: 0.0846  unsup_loss_rpn_cls: 0.0039  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0124  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:12:35 - mmengine - INFO - Iter(train) [  1350/180000]  lr: 1.0000e-02  eta: 2 days, 20:14:49  time: 1.3924  data_time: 0.0257  memory: 4504  loss: 0.2152  sup_loss_rpn_cls: 0.0119  sup_loss_rpn_bbox: 0.0096  sup_loss_cls: 0.0923  sup_acc: 97.4609  sup_loss_bbox: 0.0845  unsup_loss_rpn_cls: 0.0047  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0122  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:13:44 - mmengine - INFO - Iter(train) [  1400/180000]  lr: 1.0000e-02  eta: 2 days, 20:14:54  time: 1.3868  data_time: 0.0254  memory: 4504  loss: 0.1792  sup_loss_rpn_cls: 0.0065  sup_loss_rpn_bbox: 0.0055  sup_loss_cls: 0.0794  sup_acc: 97.8516  sup_loss_bbox: 0.0765  unsup_loss_rpn_cls: 0.0036  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0076  unsup_acc: 99.9512  unsup_loss_bbox: 0.0000
2023/06/21 06:14:08 - mmengine - INFO - Exp name: soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco_20230621_054100
2023/06/21 06:14:53 - mmengine - INFO - Iter(train) [  1450/180000]  lr: 1.0000e-02  eta: 2 days, 20:15:02  time: 1.3881  data_time: 0.0262  memory: 4504  loss: 0.2173  sup_loss_rpn_cls: 0.0096  sup_loss_rpn_bbox: 0.0083  sup_loss_cls: 0.0987  sup_acc: 97.6562  sup_loss_bbox: 0.0836  unsup_loss_rpn_cls: 0.0054  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0116  unsup_acc: 99.9023  unsup_loss_bbox: 0.0000
2023/06/21 06:16:02 - mmengine - INFO - Iter(train) [  1500/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:31  time: 1.3723  data_time: 0.0254  memory: 4504  loss: 0.1945  sup_loss_rpn_cls: 0.0095  sup_loss_rpn_bbox: 0.0067  sup_loss_cls: 0.0837  sup_acc: 99.2188  sup_loss_bbox: 0.0805  unsup_loss_rpn_cls: 0.0034  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0107  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:17:11 - mmengine - INFO - Iter(train) [  1550/180000]  lr: 1.0000e-02  eta: 2 days, 20:12:46  time: 1.3802  data_time: 0.0246  memory: 4504  loss: 0.1844  sup_loss_rpn_cls: 0.0082  sup_loss_rpn_bbox: 0.0068  sup_loss_cls: 0.0798  sup_acc: 99.0234  sup_loss_bbox: 0.0751  unsup_loss_rpn_cls: 0.0041  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0104  unsup_acc: 99.7070  unsup_loss_bbox: 0.0000
2023/06/21 06:18:20 - mmengine - INFO - Iter(train) [  1600/180000]  lr: 1.0000e-02  eta: 2 days, 20:12:20  time: 1.3837  data_time: 0.0249  memory: 4504  loss: 0.1833  sup_loss_rpn_cls: 0.0087  sup_loss_rpn_bbox: 0.0061  sup_loss_cls: 0.0775  sup_acc: 99.6094  sup_loss_bbox: 0.0791  unsup_loss_rpn_cls: 0.0029  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0092  unsup_acc: 99.2676  unsup_loss_bbox: 0.0000
2023/06/21 06:19:30 - mmengine - INFO - Iter(train) [  1650/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:27  time: 1.4016  data_time: 0.0273  memory: 4504  loss: 0.1858  sup_loss_rpn_cls: 0.0071  sup_loss_rpn_bbox: 0.0062  sup_loss_cls: 0.0803  sup_acc: 97.8516  sup_loss_bbox: 0.0792  unsup_loss_rpn_cls: 0.0036  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0093  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:20:40 - mmengine - INFO - Iter(train) [  1700/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:15  time: 1.3880  data_time: 0.0248  memory: 4504  loss: 0.1678  sup_loss_rpn_cls: 0.0056  sup_loss_rpn_bbox: 0.0070  sup_loss_cls: 0.0697  sup_acc: 97.2656  sup_loss_bbox: 0.0772  unsup_loss_rpn_cls: 0.0023  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0059  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:21:49 - mmengine - INFO - Iter(train) [  1750/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:10  time: 1.3900  data_time: 0.0244  memory: 4504  loss: 0.1869  sup_loss_rpn_cls: 0.0068  sup_loss_rpn_bbox: 0.0071  sup_loss_cls: 0.0825  sup_acc: 97.8516  sup_loss_bbox: 0.0780  unsup_loss_rpn_cls: 0.0027  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0097  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:22:59 - mmengine - INFO - Iter(train) [  1800/180000]  lr: 1.0000e-02  eta: 2 days, 20:12:57  time: 1.3890  data_time: 0.0265  memory: 4504  loss: 0.1764  sup_loss_rpn_cls: 0.0059  sup_loss_rpn_bbox: 0.0058  sup_loss_cls: 0.0760  sup_acc: 98.0469  sup_loss_bbox: 0.0761  unsup_loss_rpn_cls: 0.0033  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0093  unsup_acc: 99.8535  unsup_loss_bbox: 0.0000
2023/06/21 06:24:08 - mmengine - INFO - Iter(train) [  1850/180000]  lr: 1.0000e-02  eta: 2 days, 20:12:47  time: 1.3902  data_time: 0.0244  memory: 4504  loss: 0.1648  sup_loss_rpn_cls: 0.0059  sup_loss_rpn_bbox: 0.0070  sup_loss_cls: 0.0706  sup_acc: 97.8516  sup_loss_bbox: 0.0727  unsup_loss_rpn_cls: 0.0025  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0061  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:25:18 - mmengine - INFO - Iter(train) [  1900/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:47  time: 1.4061  data_time: 0.0273  memory: 4504  loss: 0.1711  sup_loss_rpn_cls: 0.0075  sup_loss_rpn_bbox: 0.0058  sup_loss_cls: 0.0758  sup_acc: 97.6562  sup_loss_bbox: 0.0733  unsup_loss_rpn_cls: 0.0028  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0059  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:26:28 - mmengine - INFO - Iter(train) [  1950/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:05  time: 1.3849  data_time: 0.0258  memory: 4505  loss: 0.1635  sup_loss_rpn_cls: 0.0077  sup_loss_rpn_bbox: 0.0070  sup_loss_cls: 0.0658  sup_acc: 97.2656  sup_loss_bbox: 0.0759  unsup_loss_rpn_cls: 0.0019  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0052  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:27:37 - mmengine - INFO - Exp name: soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco_20230621_054100
2023/06/21 06:27:37 - mmengine - INFO - Iter(train) [  2000/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:07  time: 1.3952  data_time: 0.0252  memory: 4505  loss: 0.1668  sup_loss_rpn_cls: 0.0044  sup_loss_rpn_bbox: 0.0059  sup_loss_cls: 0.0730  sup_acc: 97.0703  sup_loss_bbox: 0.0752  unsup_loss_rpn_cls: 0.0025  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0058  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:28:47 - mmengine - INFO - Iter(train) [  2050/180000]  lr: 1.0000e-02  eta: 2 days, 20:12:29  time: 1.3868  data_time: 0.0257  memory: 4504  loss: 0.1706  sup_loss_rpn_cls: 0.0053  sup_loss_rpn_bbox: 0.0059  sup_loss_cls: 0.0695  sup_acc: 97.0703  sup_loss_bbox: 0.0835  unsup_loss_rpn_cls: 0.0016  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0047  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:29:57 - mmengine - INFO - Iter(train) [  2100/180000]  lr: 1.0000e-02  eta: 2 days, 20:13:25  time: 1.4094  data_time: 0.0261  memory: 4504  loss: 0.1604  sup_loss_rpn_cls: 0.0057  sup_loss_rpn_bbox: 0.0064  sup_loss_cls: 0.0627  sup_acc: 98.4375  sup_loss_bbox: 0.0764  unsup_loss_rpn_cls: 0.0026  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0065  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:31:06 - mmengine - INFO - Iter(train) [  2150/180000]  lr: 1.0000e-02  eta: 2 days, 20:12:24  time: 1.3825  data_time: 0.0240  memory: 4504  loss: 0.1798  sup_loss_rpn_cls: 0.0052  sup_loss_rpn_bbox: 0.0073  sup_loss_cls: 0.0672  sup_acc: 97.2656  sup_loss_bbox: 0.0901  unsup_loss_rpn_cls: 0.0018  unsup_loss_rpn_bbox: 0.0001  unsup_loss_cls: 0.0080  unsup_acc: 99.5117  unsup_loss_bbox: 0.0000
2023/06/21 06:32:16 - mmengine - INFO - Iter(train) [  2200/180000]  lr: 1.0000e-02  eta: 2 days, 20:11:45  time: 1.3883  data_time: 0.0251  memory: 4504  loss: 0.1545  sup_loss_rpn_cls: 0.0050  sup_loss_rpn_bbox: 0.0051  sup_loss_cls: 0.0617  sup_acc: 97.2656  sup_loss_bbox: 0.0754  unsup_loss_rpn_cls: 0.0023  unsup_loss_rpn_bbox: 0.0001  unsup_loss_cls: 0.0049  unsup_acc: 99.9512  unsup_loss_bbox: 0.0000
2023/06/21 06:33:25 - mmengine - INFO - Iter(train) [  2250/180000]  lr: 1.0000e-02  eta: 2 days, 20:11:18  time: 1.3914  data_time: 0.0257  memory: 4504  loss: 0.1532  sup_loss_rpn_cls: 0.0055  sup_loss_rpn_bbox: 0.0070  sup_loss_cls: 0.0614  sup_acc: 98.2422  sup_loss_bbox: 0.0717  unsup_loss_rpn_cls: 0.0024  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0052  unsup_acc: 100.0000  unsup_loss_bbox: 0.0000
2023/06/21 06:34:35 - mmengine - INFO - Iter(train) [  2300/180000]  lr: 1.0000e-02  eta: 2 days, 20:10:31  time: 1.3865  data_time: 0.0266  memory: 4504  loss: 0.1251  sup_loss_rpn_cls: 0.0040  sup_loss_rpn_bbox: 0.0057  sup_loss_cls: 0.0431  sup_acc: 98.4375  sup_loss_bbox: 0.0607  unsup_loss_rpn_cls: 0.0019  unsup_loss_rpn_bbox: 0.0003  unsup_loss_cls: 0.0082  unsup_acc: 100.0000  unsup_loss_bbox: 0.0012
2023/06/21 06:35:44 - mmengine - INFO - Iter(train) [  2350/180000]  lr: 1.0000e-02  eta: 2 days, 20:09:29  time: 1.3830  data_time: 0.0248  memory: 4504  loss: 0.1467  sup_loss_rpn_cls: 0.0054  sup_loss_rpn_bbox: 0.0061  sup_loss_cls: 0.0552  sup_acc: 98.6328  sup_loss_bbox: 0.0605  unsup_loss_rpn_cls: 0.0045  unsup_loss_rpn_bbox: 0.0003  unsup_loss_cls: 0.0134  unsup_acc: 100.0000  unsup_loss_bbox: 0.0013
2023/06/21 06:36:53 - mmengine - INFO - Iter(train) [  2400/180000]  lr: 1.0000e-02  eta: 2 days, 20:08:43  time: 1.3875  data_time: 0.0254  memory: 4504  loss: 0.1482  sup_loss_rpn_cls: 0.0038  sup_loss_rpn_bbox: 0.0065  sup_loss_cls: 0.0575  sup_acc: 98.8281  sup_loss_bbox: 0.0642  unsup_loss_rpn_cls: 0.0028  unsup_loss_rpn_bbox: 0.0010  unsup_loss_cls: 0.0118  unsup_acc: 100.0000  unsup_loss_bbox: 0.0007
2023/06/21 06:38:04 - mmengine - INFO - Iter(train) [  2450/180000]  lr: 1.0000e-02  eta: 2 days, 20:09:41  time: 1.4166  data_time: 0.0251  memory: 4504  loss: 0.1461  sup_loss_rpn_cls: 0.0045  sup_loss_rpn_bbox: 0.0055  sup_loss_cls: 0.0548  sup_acc: 99.6094  sup_loss_bbox: 0.0657  unsup_loss_rpn_cls: 0.0033  unsup_loss_rpn_bbox: 0.0001  unsup_loss_cls: 0.0105  unsup_acc: 100.0000  unsup_loss_bbox: 0.0016
2023/06/21 06:39:14 - mmengine - INFO - Iter(train) [  2500/180000]  lr: 1.0000e-02  eta: 2 days, 20:10:06  time: 1.4084  data_time: 0.0260  memory: 4504  loss: 0.1732  sup_loss_rpn_cls: 0.0060  sup_loss_rpn_bbox: 0.0063  sup_loss_cls: 0.0646  sup_acc: 96.6797  sup_loss_bbox: 0.0712  unsup_loss_rpn_cls: 0.0062  unsup_loss_rpn_bbox: 0.0006  unsup_loss_cls: 0.0174  unsup_acc: 99.0234  unsup_loss_bbox: 0.0008
2023/06/21 06:40:26 - mmengine - INFO - Iter(train) [  2550/180000]  lr: 1.0000e-02  eta: 2 days, 20:11:17  time: 1.4228  data_time: 0.0248  memory: 4504  loss: 0.1434  sup_loss_rpn_cls: 0.0047  sup_loss_rpn_bbox: 0.0053  sup_loss_cls: 0.0554  sup_acc: 99.6094  sup_loss_bbox: 0.0643  unsup_loss_rpn_cls: 0.0019  unsup_loss_rpn_bbox: 0.0001  unsup_loss_cls: 0.0084  unsup_acc: 100.0000  unsup_loss_bbox: 0.0032
2023/06/21 06:41:35 - mmengine - INFO - Iter(train) [  2600/180000]  lr: 1.0000e-02  eta: 2 days, 20:10:48  time: 1.3953  data_time: 0.0245  memory: 4504  loss: 0.1736  sup_loss_rpn_cls: 0.0064  sup_loss_rpn_bbox: 0.0061  sup_loss_cls: 0.0607  sup_acc: 98.2422  sup_loss_bbox: 0.0742  unsup_loss_rpn_cls: 0.0059  unsup_loss_rpn_bbox: 0.0002  unsup_loss_cls: 0.0190  unsup_acc: 100.0000  unsup_loss_bbox: 0.0010
2023/06/21 06:42:45 - mmengine - INFO - Iter(train) [  2650/180000]  lr: 1.0000e-02  eta: 2 days, 20:10:26  time: 1.3975  data_time: 0.0253  memory: 4504  loss: 0.1549  sup_loss_rpn_cls: 0.0063  sup_loss_rpn_bbox: 0.0051  sup_loss_cls: 0.0583  sup_acc: 96.4844  sup_loss_bbox: 0.0709  unsup_loss_rpn_cls: 0.0024  unsup_loss_rpn_bbox: 0.0005  unsup_loss_cls: 0.0092  unsup_acc: 100.0000  unsup_loss_bbox: 0.0022
2023/06/21 06:43:55 - mmengine - INFO - Iter(train) [  2700/180000]  lr: 1.0000e-02  eta: 2 days, 20:09:56  time: 1.3959  data_time: 0.0242  memory: 4504  loss: 0.1582  sup_loss_rpn_cls: 0.0039  sup_loss_rpn_bbox: 0.0066  sup_loss_cls: 0.0589  sup_acc: 98.6328  sup_loss_bbox: 0.0657  unsup_loss_rpn_cls: 0.0047  unsup_loss_rpn_bbox: 0.0003  unsup_loss_cls: 0.0163  unsup_acc: 99.7559  unsup_loss_bbox: 0.0018
2023/06/21 06:45:04 - mmengine - INFO - Iter(train) [  2750/180000]  lr: 1.0000e-02  eta: 2 days, 20:08:23  time: 1.3768  data_time: 0.0239  memory: 4504  loss: 0.1800  sup_loss_rpn_cls: 0.0077  sup_loss_rpn_bbox: 0.0054  sup_loss_cls: 0.0698  sup_acc: 98.2422  sup_loss_bbox: 0.0787  unsup_loss_rpn_cls: 0.0036  unsup_loss_rpn_bbox: 0.0003  unsup_loss_cls: 0.0115  unsup_acc: 99.4629  unsup_loss_bbox: 0.0029
2023/06/21 06:46:13 - mmengine - INFO - Iter(train) [  2800/180000]  lr: 1.0000e-02  eta: 2 days, 20:07:05  time: 1.3812  data_time: 0.0238  memory: 4504  loss: 0.1448  sup_loss_rpn_cls: 0.0039  sup_loss_rpn_bbox: 0.0055  sup_loss_cls: 0.0561  sup_acc: 98.8281  sup_loss_bbox: 0.0694  unsup_loss_rpn_cls: 0.0024  unsup_loss_rpn_bbox: 0.0001  unsup_loss_cls: 0.0069  unsup_acc: 100.0000  unsup_loss_bbox: 0.0005
2023/06/21 06:47:23 - mmengine - INFO - Iter(train) [  2850/180000]  lr: 1.0000e-02  eta: 2 days, 20:06:33  time: 1.3958  data_time: 0.0256  memory: 4504  loss: 0.1474  sup_loss_rpn_cls: 0.0025  sup_loss_rpn_bbox: 0.0057  sup_loss_cls: 0.0505  sup_acc: 97.2656  sup_loss_bbox: 0.0682  unsup_loss_rpn_cls: 0.0034  unsup_loss_rpn_bbox: 0.0007  unsup_loss_cls: 0.0137  unsup_acc: 100.0000  unsup_loss_bbox: 0.0026
2023/06/21 06:48:33 - mmengine - INFO - Iter(train) [  2900/180000]  lr: 1.0000e-02  eta: 2 days, 20:06:34  time: 1.4070  data_time: 0.0252  memory: 4504  loss: 0.1460  sup_loss_rpn_cls: 0.0047  sup_loss_rpn_bbox: 0.0060  sup_loss_cls: 0.0505  sup_acc: 98.0469  sup_loss_bbox: 0.0736  unsup_loss_rpn_cls: 0.0019  unsup_loss_rpn_bbox: 0.0001  unsup_loss_cls: 0.0068  unsup_acc: 100.0000  unsup_loss_bbox: 0.0023
2023/06/21 06:49:43 - mmengine - INFO - Iter(train) [  2950/180000]  lr: 1.0000e-02  eta: 2 days, 20:06:12  time: 1.4004  data_time: 0.0250  memory: 4505  loss: 0.1867  sup_loss_rpn_cls: 0.0044  sup_loss_rpn_bbox: 0.0061  sup_loss_cls: 0.0618  sup_acc: 99.4141  sup_loss_bbox: 0.0757  unsup_loss_rpn_cls: 0.0106  unsup_loss_rpn_bbox: 0.0014  unsup_loss_cls: 0.0241  unsup_acc: 100.0000  unsup_loss_bbox: 0.0025
2023/06/21 06:50:53 - mmengine - INFO - Exp name: soft-teacher_faster-rcnn_r50-caffe_fpn_180k_semi-0.1-coco_20230621_054100
2023/06/21 06:50:53 - mmengine - INFO - Iter(train) [  3000/180000]  lr: 1.0000e-02  eta: 2 days, 20:05:55  time: 1.4024  data_time: 0.0268  memory: 4504  loss: 0.1432  sup_loss_rpn_cls: 0.0030  sup_loss_rpn_bbox: 0.0057  sup_loss_cls: 0.0522  sup_acc: 98.6328  sup_loss_bbox: 0.0694  unsup_loss_rpn_cls: 0.0023  unsup_loss_rpn_bbox: 0.0002  unsup_loss_cls: 0.0085  unsup_acc: 100.0000  unsup_loss_bbox: 0.0019
2023/06/21 06:52:03 - mmengine - INFO - Iter(train) [  3050/180000]  lr: 1.0000e-02  eta: 2 days, 20:05:32  time: 1.4008  data_time: 0.0247  memory: 4504  loss: 0.1395  sup_loss_rpn_cls: 0.0030  sup_loss_rpn_bbox: 0.0052  sup_loss_cls: 0.0455  sup_acc: 98.6328  sup_loss_bbox: 0.0608  unsup_loss_rpn_cls: 0.0023  unsup_loss_rpn_bbox: 0.0005  unsup_loss_cls: 0.0148  unsup_acc: 100.0000  unsup_loss_bbox: 0.0073
2023/06/21 06:53:14 - mmengine - INFO - Iter(train) [  3100/180000]  lr: 1.0000e-02  eta: 2 days, 20:05:25  time: 1.4072  data_time: 0.0253  memory: 4504  loss: 0.1429  sup_loss_rpn_cls: 0.0031  sup_loss_rpn_bbox: 0.0050  sup_loss_cls: 0.0370  sup_acc: 99.2188  sup_loss_bbox: 0.0669  unsup_loss_rpn_cls: 0.0061  unsup_loss_rpn_bbox: 0.0013  unsup_loss_cls: 0.0104  unsup_acc: 100.0000  unsup_loss_bbox: 0.0132
2023/06/21 06:54:23 - mmengine - INFO - Iter(train) [  3150/180000]  lr: 1.0000e-02  eta: 2 days, 20:04:20  time: 1.3875  data_time: 0.0250  memory: 4504  loss: 0.1283  sup_loss_rpn_cls: 0.0028  sup_loss_rpn_bbox: 0.0066  sup_loss_cls: 0.0459  sup_acc: 98.4375  sup_loss_bbox: 0.0662  unsup_loss_rpn_cls: 0.0008  unsup_loss_rpn_bbox: 0.0000  unsup_loss_cls: 0.0049  unsup_acc: 99.9512  unsup_loss_bbox: 0.0011
